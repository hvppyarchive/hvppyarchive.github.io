<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.27.1 by Michael Rose
  Copyright 2013-2025 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Reasoning effort 실험 계획 - ARCHIVE</title>
<meta name="description" content="">


  <meta name="author" content="hvppyarchive">
  
  <meta property="article:author" content="hvppyarchive">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="ARCHIVE">
<meta property="og:title" content="Reasoning effort 실험 계획">
<meta property="og:url" content="https://hvppyarchive.github.io/llm/reasoning-effort-test/">


  <meta property="og:description" content="">







  <meta property="article:published_time" content="2025-08-11T17:59:44+09:00">





  

  


<link rel="canonical" href="https://hvppyarchive.github.io/llm/reasoning-effort-test/">












<!-- end _includes/seo.html -->


<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->
<!-- hvppyarchive: add fonts -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif+KR:wght@200..900&display=swap" rel="stylesheet">

<!-- insert favicons. use https://realfavicongenerator.net/ -->
 <!-- hvppyarchive: add favicons -->
<link rel="icon" type="image/png" href="/assets/favicon/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/svg+xml" href="/assets/favicon/favicon.svg" />
<link rel="shortcut icon" href="/assets/favicon/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png" />
<link rel="manifest" href="/assets/favicon/site.webmanifest" />

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          ARCHIVE
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/year-archive/"
                
                
              >Posts</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Reasoning effort 실험 계획">
    <meta itemprop="description" content="">
    <meta itemprop="datePublished" content="2025-08-11T17:59:44+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://hvppyarchive.github.io/llm/reasoning-effort-test/" itemprop="url">Reasoning effort 실험 계획
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-11T17:59:44+09:00">2025-08-11</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p class="chat--user">

LLM 모델의 Reasoning 강도 설정을 바꿔보며 어떤 차이가 나는지 실험을 해보고 싶어. 내가 쓰는 모델은 “Reasoning effort: High"를 넣어주면 설정을 바꿀 수있어. medium, Low도 가능해. endpoint url이 주어졌을 때 실험 계획을 세우고 스텝 바이 스텝으로 알려줘.

</p>

<p>좋아요! “Reasoning effort: High/Medium/Low”를 바꿔가며 <strong>어떤 차이가 실제로 나는지</strong> 확인하려면, 변수·지표·실험 설계를 딱 정해 놓고 돌리는 게 핵심입니다. 아래는 <strong>엔드포인트 URL만 있으면</strong> 그대로 따라 할 수 있는 <strong>스텝-바이-스텝 실험 계획</strong> 이에요.</p>

<hr />

<h1 id="1-목적과-가설-정하기">1) 목적과 가설 정하기</h1>

<ol>
  <li>
    <p><strong>목적:</strong> Reasoning effort 수준에 따라 <strong>정확도/추론 성공률</strong> , <strong>지연 시간(latency)</strong> , <strong>토큰/비용</strong> 이 어떻게 달라지는지 정량 비교.</p>
  </li>
  <li>
    <p><strong>가설(예시):</strong></p>

    <ul>
      <li>
        <p>High &gt; Medium &gt; Low 순으로 정확도↑, 반대로 지연 시간·비용은 High가 가장 큼.</p>
      </li>
      <li>
        <p>난도 높은 문제(멀티스텝, 함정 포함)는 High의 이점이 더 큼.</p>
      </li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="2-비교할-조건-정의">2) 비교할 조건 정의</h1>

<ul>
  <li>
    <p><strong>독립변수:</strong> <code class="language-plaintext highlighter-rouge">reasoning_effort ∈ {low, medium, high}</code></p>
  </li>
  <li>
    <p><strong>통제변수:</strong> 동일 모델/버전, temperature(예: 0.2), max_tokens, 시스템 프롬프트, seed(가능하면 고정), API 엔드포인트.</p>
  </li>
  <li>
    <p><strong>반복수:</strong> 각 프롬프트×effort별 <strong>n=3~5회 반복</strong>(랜덤성 평균화).</p>
  </li>
  <li>
    <p><strong>평가 세트:</strong> 3개 버킷 권장</p>

    <ul>
      <li>
        <p>(A) <strong>정확/오답이 명확한 문제:</strong> 예) 수학/논리(정답 존재) 50~100문항</p>
      </li>
      <li>
        <p>(B) <strong>장문 요약/분류/정보추출:</strong> 기준 답안 또는 스코어러 있음</p>
      </li>
      <li>
        <p>(C) <strong>코딩/퍼즐/툴-이용 시나리오:</strong> 테스트케이스로 채점 가능</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>샘플 크기:</strong> 각 버킷당 최소 50개(가능하면 100개). 적을수록 반복수를 늘려 불확실성 보완.</p>
  </li>
</ul>

<hr />

<h1 id="3-지표-설계">3) 지표 설계</h1>

<p><strong>핵심 지표</strong></p>

<ul>
  <li>
    <p><strong>정확도/스코어</strong> : 정답률, F1/ROUGE/BLEU, 테스트케이스 통과율 등 태스크별 자동 채점.</p>
  </li>
  <li>
    <p><strong>지연 시간</strong> : end-to-end(요청~응답 수신) ms.</p>
  </li>
  <li>
    <p><strong>비용/토큰</strong> : input/output/reasoning 토큰(가능 시) 및 총 비용.</p>
  </li>
  <li>
    <p><strong>실패율</strong> : 타임아웃/에러율.</p>
  </li>
</ul>

<p><strong>보조 지표</strong></p>

<ul>
  <li>
    <p><strong>스텝 수 추정</strong> : 응답 길이(토큰)로 간접 추정.</p>
  </li>
  <li>
    <p><strong>일관성</strong> : 반복 응답 간 편차(분산).</p>
  </li>
</ul>

<hr />

<h1 id="4-실험-디자인">4) 실험 디자인</h1>

<ol>
  <li>
    <p><strong>페어드 테스트(권장):</strong> 같은 프롬프트를 Low/Med/High 모두에 돌려 <strong>쌍대 비교</strong>.</p>
  </li>
  <li>
    <p><strong>무작위 순서화:</strong> (프롬프트 i)×(effort j) 실행 순서를 무작위로 섞음(순서 효과 제거).</p>
  </li>
  <li>
    <p><strong>라틴 스퀘어(선택):</strong> 순서 편향이 걱정되면 적용.</p>
  </li>
  <li>
    <p><strong>리트라이 규칙:</strong> 타임아웃/429는 <strong>지수 백오프</strong> 로 2~3회 재시도, 실패는 로그에 표기.</p>
  </li>
</ol>

<hr />

<h1 id="5-데이터-포맷로그-스키마">5) 데이터 포맷(로그 스키마)</h1>

<p>각 호출마다 아래를 저장하세요(JSON line 추천).</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"prompt_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"A_023"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"bucket"</span><span class="p">:</span><span class="w"> </span><span class="s2">"math"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"effort"</span><span class="p">:</span><span class="w"> </span><span class="s2">"high|medium|low"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"trial"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
  </span><span class="nl">"request_ts"</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w">
  </span><span class="nl">"latency_ms"</span><span class="p">:</span><span class="w"> </span><span class="mi">842</span><span class="p">,</span><span class="w">
  </span><span class="nl">"input_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">312</span><span class="p">,</span><span class="w">
  </span><span class="nl">"output_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">521</span><span class="p">,</span><span class="w">
  </span><span class="nl">"reasoning_tokens"</span><span class="p">:</span><span class="w"> </span><span class="mi">409</span><span class="p">,</span><span class="w">     </span><span class="err">//</span><span class="w"> </span><span class="err">제공되면</span><span class="w">
  </span><span class="nl">"cost_usd"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0123</span><span class="p">,</span><span class="w">          </span><span class="err">//</span><span class="w"> </span><span class="err">단가표로</span><span class="w"> </span><span class="err">계산</span><span class="w">
  </span><span class="nl">"response_text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w">
  </span><span class="nl">"tool_calls"</span><span class="p">:</span><span class="w"> </span><span class="p">[],</span><span class="w">            </span><span class="err">//</span><span class="w"> </span><span class="err">있으면</span><span class="w">
  </span><span class="nl">"error"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<hr />

<h1 id="6-실행-방법엔드포인트-예시">6) 실행 방법(엔드포인트 예시)</h1>

<p>아래에서 <code class="language-plaintext highlighter-rouge">ENDPOINT_URL</code>과 <code class="language-plaintext highlighter-rouge">API_KEY</code>만 바꿔 쓰면 됩니다.<br />
Effort는 <strong>요청 바디</strong> 에 <code class="language-plaintext highlighter-rouge">reasoning_effort</code> 필드로 넣는다고 가정했습니다. (예: <code class="language-plaintext highlighter-rouge">"high"|"medium"|"low"</code>)</p>

<h2 id="a-curl-단건-테스트">(A) cURL 단건 테스트</h2>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-X</span> POST <span class="s2">"</span><span class="nv">$ENDPOINT_URL</span><span class="s2">"</span> <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Authorization: Bearer </span><span class="nv">$API_KEY</span><span class="s2">"</span> <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> <span class="se">\</span>
  <span class="nt">-d</span> <span class="s1">'{
    "model": "your-model-id",
    "reasoning_effort": "high",
    "temperature": 0.2,
    "max_tokens": 1024,
    "seed": 42,
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "문제: 12개의 사과를 3명에게 공평하게 나누면 한 사람당 몇 개인가?"}
    ]
  }'</span>
</code></pre></div></div>

<h2 id="b-파이썬-배치-스크립트재현-가능-로그-저장">(B) 파이썬 배치 스크립트(재현 가능, 로그 저장)</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">json</span><span class="p">,</span> <span class="n">random</span><span class="p">,</span> <span class="n">uuid</span>
<span class="kn">import</span> <span class="n">requests</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">ENDPOINT_URL</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">ENDPOINT_URL</span><span class="sh">"</span><span class="p">)</span>
<span class="n">API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">API_KEY</span><span class="sh">"</span><span class="p">)</span>
<span class="n">MODEL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">your-model-id</span><span class="sh">"</span>

<span class="n">HEADERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">Authorization</span><span class="sh">"</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Bearer </span><span class="si">{</span><span class="n">API_KEY</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">Content-Type</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">application/json</span><span class="sh">"</span>
<span class="p">}</span>

<span class="n">EFFORTS</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">low</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">medium</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">high</span><span class="sh">"</span><span class="p">]</span>
<span class="n">TEMPERATURE</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">MAX_TOKENS</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">REPEATS</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># 각 프롬프트×effort 반복 수
</span>
<span class="c1"># 프롬프트 목록 예시
</span><span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">prompt_id</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">M_001</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">bucket</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">math</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">세 수의 평균이 10이고...</span><span class="sh">"</span><span class="p">},</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">prompt_id</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">S_014</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">bucket</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">summary</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">아래 글을 1문장으로 요약...</span><span class="sh">"</span><span class="p">},</span>
    <span class="c1"># ... (CSV/JSON에서 로드 권장)
</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">call_model</span><span class="p">(</span><span class="n">user_text</span><span class="p">,</span> <span class="n">effort</span><span class="p">):</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">model</span><span class="sh">"</span><span class="p">:</span> <span class="n">MODEL</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">reasoning_effort</span><span class="sh">"</span><span class="p">:</span> <span class="n">effort</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">temperature</span><span class="sh">"</span><span class="p">:</span> <span class="n">TEMPERATURE</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">max_tokens</span><span class="sh">"</span><span class="p">:</span> <span class="n">MAX_TOKENS</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">seed</span><span class="sh">"</span><span class="p">:</span> <span class="n">SEED</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">messages</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful assistant.</span><span class="sh">"</span><span class="p">},</span>
            <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">user_text</span><span class="p">}</span>
        <span class="p">]</span>
    <span class="p">}</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="n">ENDPOINT_URL</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">HEADERS</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="nf">int</span><span class="p">((</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span><span class="p">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dt</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">status</span><span class="sh">"</span><span class="p">:</span> <span class="n">r</span><span class="p">.</span><span class="n">status_code</span><span class="p">,</span> <span class="sh">"</span><span class="s">body</span><span class="sh">"</span><span class="p">:</span> <span class="n">r</span><span class="p">.</span><span class="n">text</span><span class="p">}</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="nf">json</span><span class="p">()</span>
    <span class="c1"># API 사양에 맞게 파싱하세요
</span>    <span class="n">out_text</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">choices</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">usage</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">usage</span><span class="sh">"</span><span class="p">,</span> <span class="p">{})</span>
    <span class="k">return</span> <span class="n">dt</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="n">out_text</span><span class="p">,</span> <span class="sh">"</span><span class="s">usage</span><span class="sh">"</span><span class="p">:</span> <span class="n">usage</span><span class="p">},</span> <span class="bp">None</span>

<span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">2025</span><span class="p">)</span>
<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">eff</span> <span class="ow">in</span> <span class="n">EFFORTS</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">REPEATS</span><span class="p">):</span>
            <span class="n">pairs</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">item</span><span class="p">,</span> <span class="n">eff</span><span class="p">,</span> <span class="n">trial</span><span class="p">))</span>

<span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">item</span><span class="p">,</span> <span class="n">eff</span><span class="p">,</span> <span class="n">trial</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
    <span class="n">latency_ms</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="nf">call_model</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">],</span> <span class="n">eff</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="nf">str</span><span class="p">(</span><span class="n">uuid</span><span class="p">.</span><span class="nf">uuid4</span><span class="p">()),</span>
        <span class="sh">"</span><span class="s">ts</span><span class="sh">"</span><span class="p">:</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">utcnow</span><span class="p">().</span><span class="nf">isoformat</span><span class="p">(),</span>
        <span class="sh">"</span><span class="s">prompt_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="sh">"</span><span class="s">prompt_id</span><span class="sh">"</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">bucket</span><span class="sh">"</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="sh">"</span><span class="s">bucket</span><span class="sh">"</span><span class="p">],</span>
        <span class="sh">"</span><span class="s">effort</span><span class="sh">"</span><span class="p">:</span> <span class="n">eff</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">trial</span><span class="sh">"</span><span class="p">:</span> <span class="n">trial</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="n">latency_ms</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">input_tokens</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">result</span> <span class="ow">or</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">usage</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">prompt_tokens</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">output_tokens</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">result</span> <span class="ow">or</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">usage</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">completion_tokens</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">reasoning_tokens</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">result</span> <span class="ow">or</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">usage</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">reasoning_tokens</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">cost_usd</span><span class="sh">"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>  <span class="c1"># 단가표로 후처리 계산
</span>        <span class="sh">"</span><span class="s">response_text</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">result</span> <span class="ow">or</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">error</span><span class="sh">"</span><span class="p">:</span> <span class="n">err</span>
    <span class="p">}</span>
    <span class="n">rows</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="sh">"</span><span class="s">prompt_id</span><span class="sh">"</span><span class="p">],</span> <span class="n">eff</span><span class="p">,</span> <span class="n">trial</span><span class="p">,</span> <span class="sh">"</span><span class="s">latency:</span><span class="sh">"</span><span class="p">,</span> <span class="n">latency_ms</span><span class="p">,</span> <span class="sh">"</span><span class="s">ms</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ok</span><span class="sh">"</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">err</span> <span class="k">else</span> <span class="sh">"</span><span class="s">ERR</span><span class="sh">"</span><span class="p">)</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">runs.jsonl</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">utf-8</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Saved runs.jsonl</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h1 id="7-자동-채점품질-평가">7) 자동 채점/품질 평가</h1>

<ul>
  <li>
    <p><strong>정답형 문제:</strong> 정답 키와 딱 매칭(문자 정규화 후).</p>
  </li>
  <li>
    <p><strong>요약/분류:</strong> 정답 레이블/참조 요약과 비교(F1/ROUGE 등).</p>
  </li>
  <li>
    <p><strong>코딩:</strong> 테스트케이스 실행 통과율.</p>
  </li>
  <li>
    <p><strong>주관형 품질(선택):</strong> 블라인드 <strong>휴먼 평가 가이드</strong> 예시</p>

    <ul>
      <li>
        <p>관련성(0–5), 사실성(0–5), 구조/명료성(0–5), 과잉추론/환각(감점).</p>
      </li>
      <li>
        <p>평가자는 effort 값을 모른 채로 평가(이중맹검).</p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="8-분석-계획스텝별">8) 분석 계획(스텝별)</h1>

<ol>
  <li>
    <p><strong>전처리:</strong> 프롬프트·effort·trial로 그룹핑, trial 평균(또는 중위) 계산.</p>
  </li>
  <li>
    <p><strong>기본 통계:</strong> effort별 평균 정확도/지연/비용 표·박스플롯.</p>
  </li>
  <li>
    <p><strong>쌍대 비교:</strong> 같은 프롬프트 기준으로</p>

    <ul>
      <li>
        <p>정량지표(정답률 등): <strong>윌콕슨 부호순위 검정</strong> 또는 <strong>짝지은 t-검정</strong></p>
      </li>
      <li>
        <p>effort 3수준 동시 비교: <strong>반복측정 ANOVA</strong> 또는 <strong>프리드먼 검정</strong></p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>효과크기 산출:</strong> Cliff’s delta / Cohen’s d.</p>
  </li>
  <li>
    <p><strong>신뢰구간:</strong> 부트스트랩(프롬프트 단위 리샘플) 95% CI.</p>
  </li>
  <li>
    <p><strong>난이도 교호작용:</strong> 버킷(A/B/C)별로 분리해서 동일 분석.</p>
  </li>
  <li>
    <p><strong>비용-효용 곡선:</strong> x축=비용(또는 토큰), y축=정확도(또는 승률)로 <strong>프런티어</strong> 시각화.</p>
  </li>
</ol>

<hr />

<h1 id="9-결론-도출-체크리스트">9) 결론 도출 체크리스트</h1>

<ul>
  <li>
    <p>High가 <strong>얼마나</strong> 더 정확한가? (절대/상대 개선 %)</p>
  </li>
  <li>
    <p>그 개선이 <strong>통계적으로 유의</strong> 한가? (p값/CI)</p>
  </li>
  <li>
    <p><strong>추가 지연/비용 대비 가치</strong> 가 있는가? (업무 케이스별)</p>
  </li>
  <li>
    <p>어떤 <strong>태스크</strong> 에서 High의 이득이 특히 큰가?</p>
  </li>
  <li>
    <p>운영 권장치(예: “기본 Medium, 실패/난해 시 High 재시도”).</p>
  </li>
</ul>

<hr />

<h1 id="10-리스크주의-사항">10) 리스크/주의 사항</h1>

<ul>
  <li>
    <p><strong>일관된 시드·온도</strong> 로 공정성 확보.</p>
  </li>
  <li>
    <p><strong>프롬프트 누수 방지:</strong> 정답/해설을 시스템/컨텍스트에 포함하지 않기.</p>
  </li>
  <li>
    <p><strong>체인오브소트(내적추론) 노출</strong> 은 평가에 포함하되, 외부 배포/저장 정책 준수.</p>
  </li>
  <li>
    <p><strong>레이트 리밋</strong> 과 <strong>타임아웃</strong> 대비(백오프, 큐잉).</p>
  </li>
  <li>
    <p><strong>데이터 보호:</strong> 민감 데이터 비익명 전송 금지.</p>
  </li>
</ul>

<hr />

<h1 id="11-산출물템플릿">11) 산출물(템플릿)</h1>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">runs.jsonl</code> 원시 로그</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">metrics.csv</code> (프롬프트×effort 집계표)</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">report.md</code> (요약: 설정, 데이터, 결과, 결론, 한계)</p>
  </li>
</ul>

<hr />

<h1 id="12-빠른-파일럿30분-컷">12) 빠른 파일럿(30분 컷)</h1>

<ol>
  <li>
    <p>버킷 A에서 30문항만 추려서 Low/Med/High 각 2회씩.</p>
  </li>
  <li>
    <p>정확도·지연·토큰만 우선 비교.</p>
  </li>
  <li>
    <p>효과 있으면 전체 배치 확장.</p>
  </li>
</ol>

<hr />

<p>필요하면 <strong>채점 스크립트/리포트 노트북(그래프 포함)</strong>도 만들어 드릴게요.<br />
엔드포인트 사양이 약간 다르면(예: <code class="language-plaintext highlighter-rouge">reasoning_effort</code> 키 이름, usage 필드 명) 알려주시면 위 코드/스키마를 맞춰 드리겠습니다.</p>

<p class="chat--user">

데이터가 없어 이런 걸 하는 라이브러리 없나?

</p>

<p>LLM의 “Reasoning effort” 설정을 직접 비교해 보고 싶은데, 직접 데이터가 없어 번거로우시죠? 다행히, 이미 다양한 <strong>LLM 평가 라이브러리</strong> 가 있어 실험 기반 마련에 훨씬 수월하게 접근할 수 있어요.</p>

<hr />

<h2 id="주요-오픈소스-평가-라이브러리-소개">주요 오픈소스 평가 라이브러리 소개</h2>

<h3 id="1-openai-evals">1. <strong>OpenAI Evals</strong></h3>

<ul>
  <li>OpenAI에서 제공하는 공식 <strong>평가 프레임워크</strong> 로, 기본 벤치마크부터 커스텀 평가까지 지원합니다.<a href="https://github.com/openai/evals?utm_source=chatgpt.com">GitHub</a></li>
</ul>

<h3 id="2-eleutherais-lm-evaluation-harness">2. <strong>EleutherAI’s lm-evaluation-harness</strong></h3>

<ul>
  <li>수십여 개의 학술 벤치마크를 한 곳에서 실행 가능하고, 자체 API뿐 아니라 Hugging Face 모델, GPT‑NeoX, Megatron‑DeepSpeed 등 다양한 모델을 지원합니다.<a href="https://github.com/EleutherAI/lm-evaluation-harness?utm_source=chatgpt.com">GitHub</a></li>
</ul>

<h3 id="3-deepeval-confident-ai">3. <strong>DeepEval (Confident AI)</strong></h3>

<ul>
  <li>Pytest 기반으로 다양한 메트릭(요약, 환각 등)을 제공하여 손쉽게 LLM 출력을 테스트할 수 있는 오픈소스 프레임워크입니다.<a href="https://www.reddit.com/r/LLMDevs/comments/1i6r1h9/top_6_open_source_llm_evaluation_frameworks/?utm_source=chatgpt.com">Reddit</a><a href="https://medium.com/%40zilliz_learn/top-10-rag-llm-evaluation-tools-you-dont-want-to-miss-a0bfabe9ae19?utm_source=chatgpt.com">Medium</a></li>
</ul>

<h3 id="4-lighteval-hugging-face">4. <strong>LightEval (Hugging Face)</strong></h3>

<ul>
  <li>다양한 벤치마크와 메트릭을 하나의 파이프라인으로 통합한 평가 툴킷으로, Transformers, Accelerate, Hugging Face Hub와 유기적으로 연동됩니다.<a href="https://www.cohorte.co/blog/lighteval-deep-dive-hugging-faces-all-in-one-framework-for-llm-evaluation?utm_source=chatgpt.com">Cohorte</a></li>
</ul>

<h3 id="5-evidently-llm-as-a-judge">5. <strong>Evidently (LLM-as-a-Judge)</strong></h3>

<ul>
  <li>LLM을 평가자로 사용하는 “LLM‑as‑a‑Judge” 방식에 특화된 오픈소스 라이브러리로, 상세한 평가 기준과 대시보드를 제공하며 최근까지도 업데이트되고 있어요.<a href="https://www.evidentlyai.com/llm-guide/llm-as-a-judge?utm_source=chatgpt.com">Evidently AI+3</a></li>
</ul>

<h3 id="6-verdict">6. <strong>Verdict</strong></h3>

<ul>
  <li>“LLM-as-a-Judge” 접근을 강화한 오픈소스 라이브러리로, 검증, 토론(debate), 집계(aggregation) 같은 모듈 기반 평가 파이프라인을 제공해 평가 신뢰도를 높입니다.<a href="https://arxiv.org/abs/2502.18018?utm_source=chatgpt.com">arXiv</a></li>
</ul>

<h3 id="7-llm-reasoners--autorace">7. <strong>LLM Reasoners + AutoRace</strong></h3>

<ul>
  <li>체인 오브 추론(chain-of‑thought)처럼 단계별 reasoning을 자동으로 평가하는 프레임워크이며, reasoning 알고리즘을 모듈화한 라이브러리도 포함되어 있습니다.<a href="https://arxiv.org/abs/2404.05221?utm_source=chatgpt.com">arXiv</a></li>
</ul>

<h3 id="8-openr">8. <strong>OpenR</strong></h3>

<ul>
  <li>오픈소스 프레임워크로, 추론능력을 향상시키기 위한 강화학습(RL), test-time compute, 과정 감독(process supervision) 등을 통합한 플랫폼입니다.<a href="https://arxiv.org/abs/2410.09671?utm_source=chatgpt.com">arXiv</a></li>
</ul>

<hr />

<h2 id="추천-실험-활용-방안">추천 실험 활용 방안</h2>

<table>
  <thead>
    <tr>
      <th>목표</th>
      <th>추천 라이브러리</th>
      <th>활용법</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>기본적인 정확도·지연·토큰 비교</td>
      <td><strong>lm-evaluation-harness</strong> , <strong>OpenAI Evals</strong> , <strong>LightEval</strong></td>
      <td>벤치마크 태스크로 실험 자동화.</td>
    </tr>
    <tr>
      <td>출력의 질적 평가 (환각, 요약 퀄리티 등)</td>
      <td><strong>DeepEval</strong> , <strong>Evidently</strong></td>
      <td>Pytest 기반 테스트 또는 LLM-judge 활용.</td>
    </tr>
    <tr>
      <td>Reasoning 과정 분석</td>
      <td><strong>LLM Reasoners + AutoRace</strong></td>
      <td>reasoning 단계별 성능 정량화.</td>
    </tr>
    <tr>
      <td>고급 신뢰도 높은 평가</td>
      <td><strong>Verdict</strong></td>
      <td>평가자의 검증 및 합의 절차 포함.</td>
    </tr>
    <tr>
      <td>전체적인 reasoning pipeline 강화</td>
      <td><strong>OpenR</strong></td>
      <td>test-time compute + RL 통합 실험 설계.</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="요약">요약</h2>

<p>물리적인 데이터셋 없이도, 위와 같은 오픈소스 <strong>評價 라이브러리</strong> 들을 활용하면 “Reasoning effort” 설정에 따른 비교 실험 설계가 훨씬 간편해져요.</p>

<p>— <strong>기본 비교</strong> 에는 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 나 <code class="language-plaintext highlighter-rouge">OpenAI Evals</code> 추천<br />
— <strong>정성적 평가</strong> 엔 <code class="language-plaintext highlighter-rouge">DeepEval</code>, <code class="language-plaintext highlighter-rouge">Evidently</code><br />
— <strong>특화된 reasoning 평가</strong> 엔 <code class="language-plaintext highlighter-rouge">LLM Reasoners</code>, <code class="language-plaintext highlighter-rouge">Verdict</code><br />
— <strong>훈련/추론 중심 통합 실험</strong> 엔 <code class="language-plaintext highlighter-rouge">OpenR</code></p>

<p>필요하시면 해당 라이브러리 중 하나를 골라 <strong>설치부터 실험 코드 예제</strong> 까지 도와 드릴게요!</p>

<p class="chat--user">

할게 너무 많네 내가 실험하려는 모델은 gpt oss야 이미 한 사람 없을까? 우리 default 모델이 어떤 reasoning level이 default인지 간단히 실험해보고 싶어

</p>

<p>맞아요—이미 해본 사람들이 있고, 문서에도 <strong>기본값은 보통 “medium”</strong> 으로 명시돼요. 예컨대 Databricks의 reasoning 모델 가이드에 <code class="language-plaintext highlighter-rouge">reasoning_effort</code> 값으로 <code class="language-plaintext highlighter-rouge">"low"</code>, <strong><code class="language-plaintext highlighter-rouge">"medium"(default)</code></strong> , <code class="language-plaintext highlighter-rouge">"high"</code>가 나온다고 되어 있어요. 또 gpt-oss 소개/모델 카드에서도 세 레벨을 지원한다고 합니다. <a href="https://docs.databricks.com/aws/en/machine-learning/model-serving/query-reason-models?utm_source=chatgpt.com">Databricks Documentation</a><a href="https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com">OpenAI+1</a></p>

<p>다만 “우리 인프라/엔드포인트”의 <strong>실제 기본값</strong> 은 게이트웨이나 프록시에서 덮어쓸 수도 있으니, <strong>초미니 검증 실험</strong> 으로 확정하는 게 제일 깔끔해요. 아래 그대로 돌려보면 5분 컷.</p>

<hr />

<h1 id="초간단-검증-플랜-step-by-step">초간단 검증 플랜 (step-by-step)</h1>

<ol>
  <li>
    <p><strong>테스트 프롬프트 고정</strong></p>

    <ul>
      <li>짧고 정답이 있는 문제 1–2개(예: 간단 산수, 상식 문제).</li>
    </ul>
  </li>
  <li>
    <p><strong>네 가지 호출 수행</strong></p>

    <ul>
      <li>
        <p>A: <code class="language-plaintext highlighter-rouge">reasoning_effort</code> <strong>미지정</strong> (실제 기본값 체크)</p>
      </li>
      <li>
        <p>B: <code class="language-plaintext highlighter-rouge">"medium"</code></p>
      </li>
      <li>
        <p>C: <code class="language-plaintext highlighter-rouge">"low"</code></p>
      </li>
      <li>
        <p>D: <code class="language-plaintext highlighter-rouge">"high"</code></p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>로그로 비교할 항목</strong></p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">latency_ms</code>, <code class="language-plaintext highlighter-rouge">usage.reasoning_tokens</code>(지원 시), <code class="language-plaintext highlighter-rouge">completion_tokens</code>, 응답 길이/정확도.</p>
      </li>
      <li>
        <p>A와 B가 거의 동일하면 <strong>기본값=medium</strong> 으로 판단.</p>
      </li>
      <li>
        <p>C &lt; B &lt; D 순으로 <code class="language-plaintext highlighter-rouge">reasoning_tokens</code>와 지연이 증가하면 파라미터 정상 동작.</p>
      </li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="curl-예시-엔드포인트만-바꾸면-됨">cURL 예시 (엔드포인트만 바꾸면 됨)</h2>

<p>A) 기본값 확인 (미지정)</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-s</span> <span class="nt">-X</span> POST <span class="s2">"</span><span class="nv">$ENDPOINT_URL</span><span class="s2">"</span> <span class="se">\</span>
 <span class="nt">-H</span> <span class="s2">"Authorization: Bearer </span><span class="nv">$API_KEY</span><span class="s2">"</span> <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> <span class="se">\</span>
 <span class="nt">-d</span> <span class="s1">'{
   "model":"gpt-oss-20b",
   "temperature":0.2,
   "messages":[
     {"role":"system","content":"You are a helpful assistant."},
     {"role":"user","content":"12개의 사과를 3명에게 공평하게 나누면?"}
   ]
 }'</span>
</code></pre></div></div>

<p>B) Medium</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">-d</span> <span class="s1">'{
  "model":"gpt-oss-20b",
  "reasoning_effort":"medium",
  "temperature":0.2,
  "messages":[{"role":"system","content":"You are a helpful assistant."},
              {"role":"user","content":"12개의 사과를 3명에게 공평하게 나누면?"}]
}'</span>
</code></pre></div></div>

<p>C) Low / D) High는 <code class="language-plaintext highlighter-rouge">"reasoning_effort"</code> 값만 각각 <code class="language-plaintext highlighter-rouge">"low"</code>, <code class="language-plaintext highlighter-rouge">"high"</code>로 바꾸면 됩니다.</p>

<hr />

<h2 id="파이썬-스니펫-결과를-표로-비교">파이썬 스니펫 (결과를 표로 비교)</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">requests</span>
<span class="n">URL</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">ENDPOINT_URL</span><span class="sh">"</span><span class="p">);</span> <span class="n">KEY</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">API_KEY</span><span class="sh">"</span><span class="p">)</span>
<span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">Authorization</span><span class="sh">"</span><span class="p">:</span><span class="sa">f</span><span class="sh">"</span><span class="s">Bearer </span><span class="si">{</span><span class="n">KEY</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">Content-Type</span><span class="sh">"</span><span class="p">:</span><span class="sh">"</span><span class="s">application/json</span><span class="sh">"</span><span class="p">}</span>
<span class="n">payload_base</span><span class="o">=</span><span class="p">{</span>
    <span class="sh">"</span><span class="s">model</span><span class="sh">"</span><span class="p">:</span><span class="sh">"</span><span class="s">gpt-oss-20b</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">temperature</span><span class="sh">"</span><span class="p">:</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">messages</span><span class="sh">"</span><span class="p">:[</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span><span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span><span class="sh">"</span><span class="s">You are a helpful assistant.</span><span class="sh">"</span><span class="p">},</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span><span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span><span class="sh">"</span><span class="s">12개의 사과를 3명에게 공평하게 나누면?</span><span class="sh">"</span><span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">t0</span><span class="o">=</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="n">r</span><span class="o">=</span><span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="n">URL</span><span class="p">,</span><span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span><span class="n">json</span><span class="o">=</span><span class="n">p</span><span class="p">,</span><span class="n">timeout</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
    <span class="n">dt</span><span class="o">=</span><span class="nf">round</span><span class="p">((</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">j</span><span class="o">=</span><span class="n">r</span><span class="p">.</span><span class="nf">json</span><span class="p">()</span>
    <span class="n">u</span><span class="o">=</span><span class="n">j</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">usage</span><span class="sh">"</span><span class="p">,{})</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">effort</span><span class="sh">"</span><span class="p">:</span><span class="n">p</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">reasoning_effort</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">&lt;unspecified&gt;</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">latency_ms</span><span class="sh">"</span><span class="p">:</span><span class="n">dt</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">reasoning_tokens</span><span class="sh">"</span><span class="p">:</span><span class="n">u</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">reasoning_tokens</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">in_tokens</span><span class="sh">"</span><span class="p">:</span><span class="n">u</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">prompt_tokens</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">out_tokens</span><span class="sh">"</span><span class="p">:</span><span class="n">u</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">completion_tokens</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span><span class="n">j</span><span class="p">[</span><span class="sh">"</span><span class="s">choices</span><span class="sh">"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">][:</span><span class="mi">80</span><span class="p">]</span>
    <span class="p">}</span>

<span class="n">rows</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">effort</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span><span class="sh">"</span><span class="s">medium</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">low</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">high</span><span class="sh">"</span><span class="p">]:</span>
    <span class="n">p</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">payload_base</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">effort</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> <span class="n">p</span><span class="p">[</span><span class="sh">"</span><span class="s">reasoning_effort</span><span class="sh">"</span><span class="p">]</span><span class="o">=</span><span class="n">effort</span>
    <span class="n">rows</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">run</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>

<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="기대되는-판별-기준">기대되는 판별 기준</h3>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">effort=미지정</code> 과 <code class="language-plaintext highlighter-rouge">medium</code>의 <strong>지연/토큰 수가 거의 동일</strong> ⇒ 실 기본값은 <strong>medium</strong>.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">low</code>는 더 짧고 토큰 적음, <code class="language-plaintext highlighter-rouge">high</code>는 더 길고 토큰 많음 ⇒ 레벨 스위치 정상.</p>
  </li>
</ul>

<hr />

<h2 id="이미-한-사람-없을까에-대한-짧은-정리">“이미 한 사람 없을까?”에 대한 짧은 정리</h2>

<ul>
  <li>gpt-oss 출시 소개/모델 카드/플랫폼 문서에서 <strong>세 레벨(저·중·고)</strong> 지원과 <strong>기본값 medium</strong> 을 확인할 수 있습니다. 다만 배포 환경에 따라 기본값이 바뀔 수 있으니 위 미니 테스트로 <strong>우리 환경의 실제 기본값</strong> 을 확정하는 걸 권장합니다. <a href="https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com">OpenAI+1</a><a href="https://docs.databricks.com/aws/en/machine-learning/model-serving/query-reason-models?utm_source=chatgpt.com">Databricks Documentation</a></li>
</ul>

<p>원하시면 위 파이썬 스니펫을 <strong>CSV 저장/간단 그래프</strong> 까지 확장해 드릴게요.</p>

<p class="chat--user">

너무 질문이 간단한거 아니야? 그건 문제가 안돼?

</p>

<p>질문이 간단해도 <strong>기본값 확인</strong> 에는 아무 문제가 없어요.<br />
여기서 우리가 보고 싶은 건 <strong>추론 정확도</strong> 가 아니라 <strong>reasoning_effort 설정에 따른 토큰·지연 시간 변화</strong> 이기 때문이에요.</p>

<hr />

<h2 id="왜-간단한-질문이-괜찮은지">왜 간단한 질문이 괜찮은지</h2>

<ol>
  <li>
    <p><strong>목표가 “default 값이 무엇인지 확인”</strong> → 정답 여부보다 <em>응답 패턴</em> 이 핵심</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">reasoning_effort</code>를 바꿨을 때 reasoning tokens 수나 latency가 달라지는지 확인하면 충분.</li>
    </ul>
  </li>
  <li>
    <p>복잡한 질문은 오히려 변수 증가</p>

    <ul>
      <li>난이도 높은 질문은 랜덤성·창의성 요소가 커서 비교 잡음(noise) 증가.</li>
    </ul>
  </li>
  <li>
    <p>단순 질문도 reasoning 단계 수에 영향을 줄 수 있음</p>

    <ul>
      <li>High일 경우, 불필요하게도 더 장황하게 chain-of-thought을 생성할 수 있음 → 토큰/시간 차이 명확히 관찰 가능.</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="다만-이런-점-주의">다만 이런 점 주의</h2>

<ul>
  <li>
    <p>너무 trivial해서 <strong>토큰·시간 차이가 거의 없는 경우</strong> 가 있을 수 있음.<br />
→ 그럴 땐 난이도를 살짝 올린 <strong>짧은 논리 퍼즐/두세 단계 산수 문제</strong> 추천.</p>
  </li>
  <li>
    <p>같은 문제를 Low/Medium/High 모두 돌려야 비교 가능.</p>
  </li>
  <li>
    <p>결과 해석 시 <em>절대값</em> 보다 <strong>상대 비교</strong> 를 보아야 함.</p>
  </li>
</ul>

<hr />

<p>원하시면 제가 <strong>짧지만 reasoning 차이를 잘 드러내는 질문 세트</strong> 를 만들어 드릴 수 있어요.<br />
예를 들어 5~10초 내로 풀 수 있지만, reasoning effort가 높으면 불필요하게 더 풀어쓰는 문제들요.</p>

<p class="chat--user">

너무 trivial 하잖아. 유치원생 레벨

</p>

<p>맞아요 😂 “12개의 사과 나누기”는 너무 유치원 급이라 High·Medium·Low 차이가 거의 안 날 수 있어요.<br />
기본값 확인이 목적이라도, <strong>짧지만 추론 단계를 2~4단계 거치게 만드는 질문</strong> 을 쓰면 차이가 훨씬 잘 드러납니다.</p>

<hr />

<h2 id="reasoning-차이를-잘-드러내는-간단짧은-예시">Reasoning 차이를 잘 드러내는 간단·짧은 예시</h2>

<ol>
  <li><strong>2단계 산수 퍼즐</strong></li>
</ol>

<blockquote>
  <p>3개의 상자에 각각 4, 7, 9개의 사탕이 있다. 상자 2에서 5개를 꺼내 상자 1에 넣고, 상자 3에서 2개를 꺼내 상자 2에 넣으면, 각 상자에는 몇 개씩 남는가?</p>
</blockquote>

<ol>
  <li><strong>간단 논리 문제</strong></li>
</ol>

<blockquote>
  <p>철수, 영희, 민수는 달리기 시합을 했다. 철수는 영희보다 빠르고, 영희는 민수보다 느리다. 누가 1등인가?</p>
</blockquote>

<ol>
  <li><strong>날짜 계산</strong></li>
</ol>

<blockquote>
  <p>오늘이 2025년 8월 11일이라면, 45일 후는 무슨 요일인가?</p>
</blockquote>

<ol>
  <li><strong>짧은 조건 추론</strong></li>
</ol>

<blockquote>
  <p>사과는 500g, 배는 700g이다. 사과 3개와 배 2개의 총 무게는 몇 kg인가?</p>
</blockquote>

<ol>
  <li><strong>패턴 완성</strong></li>
</ol>

<blockquote>
  <p>수열 2, 4, 8, 16, ? 다음 숫자는?</p>
</blockquote>

<hr />

<h2 id="이유">이유</h2>

<ul>
  <li>
    <p>이런 문제들은 <strong>High reasoning effort</strong> 일 때 불필요하게 세세한 Chain-of-Thought을 생성하므로 토큰·지연 차이가 확연.</p>
  </li>
  <li>
    <p>Medium은 필요한 계산만, Low는 더 요약된 추론만 제공하는 경향.</p>
  </li>
  <li>
    <p>정답이 명확해서 비교 시 혼동 없음.</p>
  </li>
</ul>

<hr />

<p>원하시면 제가 이 문제들로 <strong>미니 default 값 검증 스크립트</strong> 를 만들어 드릴게요.<br />
그러면 바로 한 번에 Low/Medium/High &amp; 미지정 네 가지 호출을 비교할 수 있습니다.<br />
그렇게 할까요?</p>

<p class="chat--user">

응 스크립트 만들어줘

</p>

<p>완료! 바로 돌릴 수 있는 <strong>미니 기본값 검증 스크립트</strong> 를 만들어 놨어요.</p>

<p>Download the script (gpt_oss_effort_smoke_test.py)</p>

<h3 id="어떻게-쓰나요-step-by-step">어떻게 쓰나요? (step-by-step)</h3>

<ol>
  <li>환경변수 설정</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">ENDPOINT_URL</span><span class="o">=</span><span class="s2">"https://&lt;your-endpoint&gt;"</span>
<span class="nb">export </span><span class="nv">API_KEY</span><span class="o">=</span><span class="s2">"sk-..."</span>
</code></pre></div></div>

<ol>
  <li>실행</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python gpt_oss_effort_smoke_test.py <span class="nt">--model</span> gpt-oss-20b <span class="nt">--repeats</span> 2
</code></pre></div></div>

<ul>
  <li>
    <p>각 프롬프트에 대해 <strong>effort 미지정 / low / medium / high</strong> 4가지로 호출합니다.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">runs.jsonl</code>(원시 로그)과 <code class="language-plaintext highlighter-rouge">summary.csv</code>(요약 평균치)를 저장하고, 콘솔에 노력수준별 평균 <strong>latency / tokens</strong> 를 표로 출력합니다.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">usage.reasoning_tokens</code>가 API에 있으면 같이 집계합니다.</p>
  </li>
</ul>

<h3 id="해석-팁">해석 팁</h3>

<ul>
  <li>
    <p>콘솔 표에서 <strong><code class="language-plaintext highlighter-rouge">&lt;unspecified&gt;</code>와 <code class="language-plaintext highlighter-rouge">medium</code>이 거의 동일</strong>하면, 여러분 환경의 <strong>기본값=medium</strong> 일 가능성이 높습니다.</p>
  </li>
  <li>
    <p>보통 토큰/지연은 <strong>low &lt; medium &lt; high</strong> 순으로 증가합니다.</p>
  </li>
</ul>

<p>원하면 <code class="language-plaintext highlighter-rouge">CSV → 그래프(plot)</code> 버전도 바로 만들어 드릴게요.</p>

<p class="chat--user">

<code class="language-plaintext highlighter-rouge">python
# Create a ready-to-run Python script for mini default verification of reasoning_effort.
script = r'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gpt_oss_effort_smoke_test.py

Mini smoke test to infer the default reasoning_effort for your GPT-OSS endpoint
and verify Low/Medium/High switches affect latency and tokens.

USAGE
-----
1) Set environment variables:
   export ENDPOINT_URL="https://&lt;your-endpoint&gt;"
   export API_KEY="sk-..."
2) (Optional) Choose model id via CLI: --model gpt-oss-20b
3) Run:
   python gpt_oss_effort_smoke_test.py --repeats 2

This will:
- Send a compact set of short-but-not-trivial prompts.
- Call the endpoint with four variants per prompt:
    A) effort unspecified  (to detect actual DEFAULT)
    B) effort = "medium"
    C) effort = "low"
    D) effort = "high"
- Log per-call latency, tokens, and short text preview.
- Save results to runs.jsonl and summary.csv.
- Print a quick table showing means by effort (latency / tokens).

Notes
-----
- The script assumes an OpenAI-compatible chat completions API that returns:
    { choices: [{ message: { content: str }}],
      usage: { prompt_tokens, completion_tokens, reasoning_tokens? } }
- If your API names differ, adjust parse_usage().
- The script retries transient HTTP errors with backoff.
"""

import argparse
import json
import os
import random
import sys
import time
from datetime import datetime
from typing import Any, Dict, Optional

import requests

# ---------- Configurable defaults ----------

DEFAULT_MODEL = "gpt-oss-20b"
DEFAULT_TEMPERATURE = 0.2
DEFAULT_MAX_TOKENS = 512
DEFAULT_SEED = 42
DEFAULT_TIMEOUT = 60
DEFAULT_REPEATS = 2

PROMPTS = [
    {
        "id": "math_boxes",
        "text": (
            "3개의 상자에 각각 4, 7, 9개의 사탕이 있다. "
            "상자 2에서 5개를 꺼내 상자 1에 넣고, 상자 3에서 2개를 꺼내 상자 2에 넣으면, "
            "각 상자에는 몇 개씩 남는가? 최종 결과만 한국어로 말해줘."
        ),
    },
    {
        "id": "logic_race",
        "text": (
            "철수, 영희, 민수는 달리기 시합을 했다. 철수는 영희보다 빠르고, "
            "영희는 민수보다 느리다. 누가 1등인가? 한 단어로만 답해."
        ),
    },
    {
        "id": "date_calc",
        "text": (
            "오늘이 2025년 8월 11일이라면, 45일 후는 무슨 요일인가?"
            " 한국 시간대를 기준으로, 요일만 한국어로 답해."
        ),
    },
    {
        "id": "weight_sum",
        "text": (
            "사과는 500g, 배는 700g이다. 사과 3개와 배 2개의 총 무게는 몇 kg인가? "
            "소수점 둘째 자리까지 kg 단위로만 답해."
        ),
    },
    {
        "id": "sequence",
        "text": "수열 2, 4, 8, 16, ? 다음 숫자는? 숫자만."
    },
]

EFFORT_LEVELS = [None, "medium", "low", "high"]  # None = unspecified (to detect actual default)

# ---------- Helpers ----------

def env(key: str, default: Optional[str] = None) -&gt; str:
    val = os.getenv(key, default)
    if val is None:
        print(f"[ERROR] Missing environment variable: {key}", file=sys.stderr)
        sys.exit(1)
    return val

def parse_usage(obj: Dict[str, Any]) -&gt; Dict[str, Optional[int]]:
    usage = obj.get("usage", {}) or {}
    return {
        "prompt_tokens": usage.get("prompt_tokens"),
        "completion_tokens": usage.get("completion_tokens"),
        "reasoning_tokens": usage.get("reasoning_tokens"),  # optional
        "total_tokens": usage.get("total_tokens"),
    }

def short(s: Optional[str], n: int = 80) -&gt; str:
    if not s:
        return ""
    s = s.replace("\n", " ").strip()
    return s[:n] + ("…" if len(s) &gt; n else "")

def post_with_retries(url: str, headers: Dict[str, str], payload: Dict[str, Any], timeout: int) -&gt; requests.Response:
    backoffs = [0.5, 1.0, 2.0]
    for i, delay in enumerate([0.0] + backoffs):
        if delay:
            time.sleep(delay)
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=timeout)
            if resp.status_code in (429, 500, 502, 503, 504):
                # transient; let the loop retry
                last = resp
                continue
            return resp
        except requests.RequestException as e:
            last = e  # type: ignore[assignment]
    # On failure after retries, raise or return last response if available
    if isinstance(last, requests.Response):
        return last
    raise RuntimeError(f"HTTP error after retries: {last}")

def call_once(endpoint: str, api_key: str, model: str, user_text: str,
              effort: Optional[str], temperature: float, max_tokens: int,
              seed: Optional[int], timeout: int) -&gt; Dict[str, Any]:
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": user_text},
    ]
    body: Dict[str, Any] = {
        "model": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "messages": messages,
    }
    if seed is not None:
        body["seed"] = seed
    if effort is not None:
        body["reasoning_effort"] = effort

    t0 = time.time()
    resp = post_with_retries(endpoint, headers, body, timeout=timeout)
    elapsed_ms = int(round((time.time() - t0) * 1000))

    result: Dict[str, Any] = {
        "status": resp.status_code,
        "latency_ms": elapsed_ms,
        "response_text": None,
        "usage": None,
        "raw": None,
        "error": None,
    }

    try:
        data = resp.json()
    except Exception as e:
        result["error"] = f"Non-JSON response: {resp.text[:200]} ({e})"
        return result

    result["raw"] = data
    if resp.status_code != 200:
        result["error"] = data
        return result

    try:
        text = data["choices"][0]["message"]["content"]
    except Exception:
        text = None
    result["response_text"] = text
    result["usage"] = parse_usage(data)
    return result

def mean(xs):
    vals = [x for x in xs if isinstance(x, (int, float))]
    return sum(vals)/len(vals) if vals else None

def safe_int(x):
    return int(x) if isinstance(x, (int, float)) else None

# ---------- Main ----------

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", default=DEFAULT_MODEL)
    parser.add_argument("--repeats", type=int, default=DEFAULT_REPEATS,
                        help="Number of repeats per (prompt, effort) pair")
    parser.add_argument("--timeout", type=int, default=DEFAULT_TIMEOUT)
    parser.add_argument("--temperature", type=float, default=DEFAULT_TEMPERATURE)
    parser.add_argument("--max_tokens", type=int, default=DEFAULT_MAX_TOKENS)
    parser.add_argument("--no_seed", action="store_true", help="Do not send seed")
    args = parser.parse_args()

    endpoint = env("ENDPOINT_URL")
    api_key = env("API_KEY")
    model = args.model
    seed = None if args.no_seed else DEFAULT_SEED

    random.seed(2025)
    pairs = []
    for p in PROMPTS:
        for eff in EFFORT_LEVELS:
            for trial in range(args.repeats):
                pairs.append((p, eff, trial))
    random.shuffle(pairs)

    runs_path = "runs.jsonl"
    summary_rows = []
    n_ok = 0
    n_err = 0

    with open(runs_path, "w", encoding="utf-8") as f:
        for p, eff, trial in pairs:
            res = call_once(
                endpoint=endpoint, api_key=api_key, model=model,
                user_text=p["text"], effort=eff, temperature=args.temperature,
                max_tokens=args.max_tokens, seed=seed, timeout=args.timeout
            )
            row = {
                "ts": datetime.utcnow().isoformat(),
                "prompt_id": p["id"],
                "effort": eff if eff is not None else "&lt;unspecified&gt;",
                "trial": trial,
                "status": res["status"],
                "latency_ms": res["latency_ms"],
                "prompt_tokens": (res["usage"] or {}).get("prompt_tokens") if res["usage"] else None,
                "completion_tokens": (res["usage"] or {}).get("completion_tokens") if res["usage"] else None,
                "reasoning_tokens": (res["usage"] or {}).get("reasoning_tokens") if res["usage"] else None,
                "total_tokens": (res["usage"] or {}).get("total_tokens") if res["usage"] else None,
                "text_preview": short(res["response_text"], 120),
                "error": res["error"],
            }
            f.write(json.dumps(row, ensure_ascii=False) + "\n")
            if res["error"]:
                n_err += 1
            else:
                n_ok += 1
            summary_rows.append(row)

    # Aggregate means by effort
    by_effort = {}
    for r in summary_rows:
        e = r["effort"]
        by_effort.setdefault(e, {"latency": [], "comp": [], "reason": [], "total": []})
        if r["latency_ms"] is not None:
            by_effort[e]["latency"].append(r["latency_ms"])
        if r["completion_tokens"] is not None:
            by_effort[e]["comp"].append(r["completion_tokens"])
        if r["reasoning_tokens"] is not None:
            by_effort[e]["reason"].append(r["reasoning_tokens"])
        if r["total_tokens"] is not None:
            by_effort[e]["total"].append(r["total_tokens"])

    # Print quick table
    print("\n=== Quick Means by Effort ===")
    print("Effort           | Latency(ms) | OutTokens | ReasoningTokens | TotalTokens")
    print("-----------------+-------------+-----------+------------------+------------")
    def fmt(x):
        return f"{x:.1f}" if isinstance(x, (int, float)) else "-"
    for e in ["&lt;unspecified&gt;", "low", "medium", "high"]:
        mlat = mean(by_effort.get(e, {}).get("latency", []))
        mout = mean(by_effort.get(e, {}).get("comp", []))
        mrea = mean(by_effort.get(e, {}).get("reason", []))
        mtot = mean(by_effort.get(e, {}).get("total", []))
        print(f"{e:16} | {fmt(mlat):&gt;11} | {fmt(mout):&gt;9} | {fmt(mrea):&gt;16} | {fmt(mtot):&gt;10}")

    # Save a compact CSV summary
    csv_path = "summary.csv"
    try:
        import csv
        with open(csv_path, "w", newline="", encoding="utf-8") as cf:
            writer = csv.writer(cf)
            writer.writerow(["effort","mean_latency_ms","mean_completion_tokens","mean_reasoning_tokens","mean_total_tokens"])
            for e in ["&lt;unspecified&gt;", "low", "medium", "high"]:
                mlat = mean(by_effort.get(e, {}).get("latency", []))
                mout = mean(by_effort.get(e, {}).get("comp", []))
                mrea = mean(by_effort.get(e, {}).get("reason", []))
                mtot = mean(by_effort.get(e, {}).get("total", []))
                writer.writerow([e, f"{mlat:.1f}" if mlat else "", f"{mout:.1f}" if mout else "", f"{mrea:.1f}" if mrea else "", f"{mtot:.1f}" if mtot else ""])
        print(f"\nSaved: {csv_path}")
    except Exception as e:
        print(f"[WARN] CSV write failed: {e}")

    print(f"\nSaved raw runs to: {runs_path}")
    print(f"OK: {n_ok}, ERR: {n_err}")
    print("\nInterpretation tip:")
    print("- If '&lt;unspecified&gt;' and 'medium' are nearly identical across latency/tokens, your gateway default is likely 'medium'.")
    print("- Expect tokens/latency trend: low &lt; medium &lt; high (if reasoning tokens are exposed, same order).")

if __name__ == "__main__":
    main()
'''
with open('/mnt/data/gpt_oss_effort_smoke_test.py', 'w', encoding='utf-8') as f:
    f.write(script)
print("Script written to /mnt/data/gpt_oss_effort_smoke_test.py")
</code>

</p>

<p>네, 이 코드 그대로 <code class="language-plaintext highlighter-rouge">/mnt/data/gpt_oss_effort_smoke_test.py</code> 에 저장돼 있어서 바로 다운로드 후 실행하시면 돼요.</p>

<p>📥 gpt_oss_effort_smoke_test.py 받기</p>

<hr />

<h3 id="실행-방법-요약">실행 방법 요약</h3>

<ol>
  <li>환경변수 설정</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">ENDPOINT_URL</span><span class="o">=</span><span class="s2">"https://&lt;your-endpoint&gt;"</span>
<span class="nb">export </span><span class="nv">API_KEY</span><span class="o">=</span><span class="s2">"sk-..."</span>
</code></pre></div></div>

<ol>
  <li>스크립트 실행</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python gpt_oss_effort_smoke_test.py <span class="nt">--model</span> gpt-oss-20b <span class="nt">--repeats</span> 2
</code></pre></div></div>

<ol>
  <li>결과 확인</li>
</ol>

<ul>
  <li>
    <p>콘솔 표: effort별 평균 <strong>latency / tokens</strong></p>
  </li>
  <li>
    <p>파일:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">runs.jsonl</code>: 모든 호출 기록</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">summary.csv</code>: 평균치 요약</p>
      </li>
    </ul>
  </li>
</ul>

<p><strong>팁</strong></p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">&lt;unspecified&gt;</code>와 <code class="language-plaintext highlighter-rouge">medium</code>이 비슷하면 default가 medium일 가능성 높음</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">low &lt; medium &lt; high</code> 순으로 reasoning_tokens와 latency가 증가하는지 확인</p>
  </li>
</ul>

<p class="chat--user">

<code class="language-plaintext highlighter-rouge">python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
gpt_oss_effort_smoke_test.py

Mini smoke test to infer the default reasoning_effort for your GPT-OSS endpoint
and verify Low/Medium/High switches affect latency and tokens.

USAGE
-----
1) Set environment variables:
   export ENDPOINT_URL="https://&lt;your-endpoint&gt;"
   export API_KEY="sk-..."
2) (Optional) Choose model id via CLI: --model gpt-oss-20b
3) Run:
   python gpt_oss_effort_smoke_test.py --repeats 2

This will:
- Send a compact set of short-but-not-trivial prompts.
- Call the endpoint with four variants per prompt:
    A) effort unspecified  (to detect actual DEFAULT)
    B) effort = "medium"
    C) effort = "low"
    D) effort = "high"
- Log per-call latency, tokens, and short text preview.
- Save results to runs.jsonl and summary.csv.
- Print a quick table showing means by effort (latency / tokens).

Notes
-----
- The script assumes an OpenAI-compatible chat completions API that returns:
    { choices: [{ message: { content: str }}],
      usage: { prompt_tokens, completion_tokens, reasoning_tokens? } }
- If your API names differ, adjust parse_usage().
- The script retries transient HTTP errors with backoff.
"""

import argparse
import json
import os
import random
import sys
import time
from datetime import datetime
from typing import Any, Dict, Optional

import requests

# ---------- Configurable defaults ----------

DEFAULT_MODEL = "gpt-oss-20b"
DEFAULT_TEMPERATURE = 0.2
DEFAULT_MAX_TOKENS = 512
DEFAULT_SEED = 42
DEFAULT_TIMEOUT = 60
DEFAULT_REPEATS = 2

PROMPTS = [
    {
        "id": "math_boxes",
        "text": (
            "3개의 상자에 각각 4, 7, 9개의 사탕이 있다. "
            "상자 2에서 5개를 꺼내 상자 1에 넣고, 상자 3에서 2개를 꺼내 상자 2에 넣으면, "
            "각 상자에는 몇 개씩 남는가? 최종 결과만 한국어로 말해줘."
        ),
    },
    {
        "id": "logic_race",
        "text": (
            "철수, 영희, 민수는 달리기 시합을 했다. 철수는 영희보다 빠르고, "
            "영희는 민수보다 느리다. 누가 1등인가? 한 단어로만 답해."
        ),
    },
    {
        "id": "date_calc",
        "text": (
            "오늘이 2025년 8월 11일이라면, 45일 후는 무슨 요일인가?"
            " 한국 시간대를 기준으로, 요일만 한국어로 답해."
        ),
    },
    {
        "id": "weight_sum",
        "text": (
            "사과는 500g, 배는 700g이다. 사과 3개와 배 2개의 총 무게는 몇 kg인가? "
            "소수점 둘째 자리까지 kg 단위로만 답해."
        ),
    },
    {
        "id": "sequence",
        "text": "수열 2, 4, 8, 16, ? 다음 숫자는? 숫자만."
    },
]

EFFORT_LEVELS = [None, "medium", "low", "high"]  # None = unspecified (to detect actual default)

# ---------- Helpers ----------

def env(key: str, default: Optional[str] = None) -&gt; str:
    val = os.getenv(key, default)
    if val is None:
        print(f"[ERROR] Missing environment variable: {key}", file=sys.stderr)
        sys.exit(1)
    return val

def parse_usage(obj: Dict[str, Any]) -&gt; Dict[str, Optional[int]]:
    usage = obj.get("usage", {}) or {}
    return {
        "prompt_tokens": usage.get("prompt_tokens"),
        "completion_tokens": usage.get("completion_tokens"),
        "reasoning_tokens": usage.get("reasoning_tokens"),  # optional
        "total_tokens": usage.get("total_tokens"),
    }

def short(s: Optional[str], n: int = 80) -&gt; str:
    if not s:
        return ""
    s = s.replace("\n", " ").strip()
    return s[:n] + ("…" if len(s) &gt; n else "")

def post_with_retries(url: str, headers: Dict[str, str], payload: Dict[str, Any], timeout: int) -&gt; requests.Response:
    backoffs = [0.5, 1.0, 2.0]
    for i, delay in enumerate([0.0] + backoffs):
        if delay:
            time.sleep(delay)
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=timeout)
            if resp.status_code in (429, 500, 502, 503, 504):
                # transient; let the loop retry
                last = resp
                continue
            return resp
        except requests.RequestException as e:
            last = e  # type: ignore[assignment]
    # On failure after retries, raise or return last response if available
    if isinstance(last, requests.Response):
        return last
    raise RuntimeError(f"HTTP error after retries: {last}")

def call_once(endpoint: str, api_key: str, model: str, user_text: str,
              effort: Optional[str], temperature: float, max_tokens: int,
              seed: Optional[int], timeout: int) -&gt; Dict[str, Any]:
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": user_text},
    ]
    body: Dict[str, Any] = {
        "model": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "messages": messages,
    }
    if seed is not None:
        body["seed"] = seed
    if effort is not None:
        body["reasoning_effort"] = effort

    t0 = time.time()
    resp = post_with_retries(endpoint, headers, body, timeout=timeout)
    elapsed_ms = int(round((time.time() - t0) * 1000))

    result: Dict[str, Any] = {
        "status": resp.status_code,
        "latency_ms": elapsed_ms,
        "response_text": None,
        "usage": None,
        "raw": None,
        "error": None,
    }

    try:
        data = resp.json()
    except Exception as e:
        result["error"] = f"Non-JSON response: {resp.text[:200]} ({e})"
        return result

    result["raw"] = data
    if resp.status_code != 200:
        result["error"] = data
        return result

    try:
        text = data["choices"][0]["message"]["content"]
    except Exception:
        text = None
    result["response_text"] = text
    result["usage"] = parse_usage(data)
    return result

def mean(xs):
    vals = [x for x in xs if isinstance(x, (int, float))]
    return sum(vals)/len(vals) if vals else None

def safe_int(x):
    return int(x) if isinstance(x, (int, float)) else None

# ---------- Main ----------

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", default=DEFAULT_MODEL)
    parser.add_argument("--repeats", type=int, default=DEFAULT_REPEATS,
                        help="Number of repeats per (prompt, effort) pair")
    parser.add_argument("--timeout", type=int, default=DEFAULT_TIMEOUT)
    parser.add_argument("--temperature", type=float, default=DEFAULT_TEMPERATURE)
    parser.add_argument("--max_tokens", type=int, default=DEFAULT_MAX_TOKENS)
    parser.add_argument("--no_seed", action="store_true", help="Do not send seed")
    args = parser.parse_args()

    endpoint = env("ENDPOINT_URL")
    api_key = env("API_KEY")
    model = args.model
    seed = None if args.no_seed else DEFAULT_SEED

    random.seed(2025)
    pairs = []
    for p in PROMPTS:
        for eff in EFFORT_LEVELS:
            for trial in range(args.repeats):
                pairs.append((p, eff, trial))
    random.shuffle(pairs)

    runs_path = "runs.jsonl"
    summary_rows = []
    n_ok = 0
    n_err = 0

    with open(runs_path, "w", encoding="utf-8") as f:
        for p, eff, trial in pairs:
            res = call_once(
                endpoint=endpoint, api_key=api_key, model=model,
                user_text=p["text"], effort=eff, temperature=args.temperature,
                max_tokens=args.max_tokens, seed=seed, timeout=args.timeout
            )
            row = {
                "ts": datetime.utcnow().isoformat(),
                "prompt_id": p["id"],
                "effort": eff if eff is not None else "&lt;unspecified&gt;",
                "trial": trial,
                "status": res["status"],
                "latency_ms": res["latency_ms"],
                "prompt_tokens": (res["usage"] or {}).get("prompt_tokens") if res["usage"] else None,
                "completion_tokens": (res["usage"] or {}).get("completion_tokens") if res["usage"] else None,
                "reasoning_tokens": (res["usage"] or {}).get("reasoning_tokens") if res["usage"] else None,
                "total_tokens": (res["usage"] or {}).get("total_tokens") if res["usage"] else None,
                "text_preview": short(res["response_text"], 120),
                "error": res["error"],
            }
            f.write(json.dumps(row, ensure_ascii=False) + "\n")
            if res["error"]:
                n_err += 1
            else:
                n_ok += 1
            summary_rows.append(row)

    # Aggregate means by effort
    by_effort = {}
    for r in summary_rows:
        e = r["effort"]
        by_effort.setdefault(e, {"latency": [], "comp": [], "reason": [], "total": []})
        if r["latency_ms"] is not None:
            by_effort[e]["latency"].append(r["latency_ms"])
        if r["completion_tokens"] is not None:
            by_effort[e]["comp"].append(r["completion_tokens"])
        if r["reasoning_tokens"] is not None:
            by_effort[e]["reason"].append(r["reasoning_tokens"])
        if r["total_tokens"] is not None:
            by_effort[e]["total"].append(r["total_tokens"])

    # Print quick table
    print("\n=== Quick Means by Effort ===")
    print("Effort           | Latency(ms) | OutTokens | ReasoningTokens | TotalTokens")
    print("-----------------+-------------+-----------+------------------+------------")
    def fmt(x):
        return f"{x:.1f}" if isinstance(x, (int, float)) else "-"
    for e in ["&lt;unspecified&gt;", "low", "medium", "high"]:
        mlat = mean(by_effort.get(e, {}).get("latency", []))
        mout = mean(by_effort.get(e, {}).get("comp", []))
        mrea = mean(by_effort.get(e, {}).get("reason", []))
        mtot = mean(by_effort.get(e, {}).get("total", []))
        print(f"{e:16} | {fmt(mlat):&gt;11} | {fmt(mout):&gt;9} | {fmt(mrea):&gt;16} | {fmt(mtot):&gt;10}")

    # Save a compact CSV summary
    csv_path = "summary.csv"
    try:
        import csv
        with open(csv_path, "w", newline="", encoding="utf-8") as cf:
            writer = csv.writer(cf)
            writer.writerow(["effort","mean_latency_ms","mean_completion_tokens","mean_reasoning_tokens","mean_total_tokens"])
            for e in ["&lt;unspecified&gt;", "low", "medium", "high"]:
                mlat = mean(by_effort.get(e, {}).get("latency", []))
                mout = mean(by_effort.get(e, {}).get("comp", []))
                mrea = mean(by_effort.get(e, {}).get("reason", []))
                mtot = mean(by_effort.get(e, {}).get("total", []))
                writer.writerow([e, f"{mlat:.1f}" if mlat else "", f"{mout:.1f}" if mout else "", f"{mrea:.1f}" if mrea else "", f"{mtot:.1f}" if mtot else ""])
        print(f"\nSaved: {csv_path}")
    except Exception as e:
        print(f"[WARN] CSV write failed: {e}")

    print(f"\nSaved raw runs to: {runs_path}")
    print(f"OK: {n_ok}, ERR: {n_err}")
    print("\nInterpretation tip:")
    print("- If '&lt;unspecified&gt;' and 'medium' are nearly identical across latency/tokens, your gateway default is likely 'medium'.")
    print("- Expect tokens/latency trend: low &lt; medium &lt; high (if reasoning tokens are exposed, same order).")

if __name__ == "__main__":
    main()
</code>

</p>

<p>이 스크립트는 그대로 실행해도 <code class="language-plaintext highlighter-rouge">gpt-oss</code> 기본 reasoning_effort 값을 빠르게 확인할 수 있게 잘 짜여 있어요.</p>

<h3 id="요약-1">요약</h3>

<ul>
  <li>
    <p><strong>프롬프트</strong> : 너무 trivial하지 않고 reasoning 차이를 드러낼 수 있는 5문항.</p>
  </li>
  <li>
    <p><strong>비교 모드</strong> :</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">&lt;unspecified&gt;</code> (미지정 → default 값 확인)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">low</code>, <code class="language-plaintext highlighter-rouge">medium</code>, <code class="language-plaintext highlighter-rouge">high</code></p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>측정 지표</strong> :</p>

    <ul>
      <li>
        <p>latency(ms)</p>
      </li>
      <li>
        <p>prompt/completion/reasoning/total tokens</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>출력</strong> :</p>

    <ul>
      <li>
        <p>콘솔에 평균 표</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">runs.jsonl</code> (원시 로그)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">summary.csv</code> (평균 요약)</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="실행-방법">실행 방법</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">ENDPOINT_URL</span><span class="o">=</span><span class="s2">"https://&lt;your-endpoint&gt;"</span>
<span class="nb">export </span><span class="nv">API_KEY</span><span class="o">=</span><span class="s2">"sk-..."</span>

python gpt_oss_effort_smoke_test.py <span class="nt">--model</span> gpt-oss-20b <span class="nt">--repeats</span> 2
</code></pre></div></div>

<h3 id="결과-해석">결과 해석</h3>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">&lt;unspecified&gt;</code>와 <code class="language-plaintext highlighter-rouge">medium</code>이 거의 동일 → default = medium 가능성 큼</p>
  </li>
  <li>
    <p>reasoning_tokens / latency 순서: <code class="language-plaintext highlighter-rouge">low &lt; medium &lt; high</code>이면 정상 동작</p>
  </li>
</ul>

<p>원하면 여기에 <strong>CSV 결과를 시각화하는 플롯 코드</strong> 를 붙여서, 한눈에 비교할 수 있게 만들어 드릴까요?</p>

        
      </section>

      <footer class="page__meta">
        
        


  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#llm" class="page__taxonomy-item p-category" rel="tag">llm</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2025-08-11T17:59:44+09:00">2025-08-11</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/llm/vllm-cline-connection-debugging/" class="pagination--pager" title="vLLM Cline 연결 디버깅">Previous</a>
    
    
      <a href="/llm/openwebui-serve/" class="pagination--pager" title="OpenWebUI 셋업 방법">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
    
<div class="page__related">
  
  <h2 class="page__related-title">You may also enjoy</h2>
  <div class="grid__wrapper">
    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/2025-08-19-python-repr-vs-str/" rel="permalink">
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-21T17:30:43+09:00">2025-08-21</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/python-textbuffer/" rel="permalink">Python TextBuffer 구현
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-21T17:30:40+09:00">2025-08-21</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/llm/simple-chatbot-client/" rel="permalink">LLM Chatbot Client Plan
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-21T13:53:19+09:00">2025-08-21</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/python-dataclass-method/" rel="permalink">untitled
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-20T17:53:48+09:00">2025-08-20</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

    
  </div>
</div>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
  </ul>
</div>


<div class="page__footer-copyright">&copy; 2013 - 2025 <a href="https://hvppyarchive.github.io">ARCHIVE</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>






  </body>
</html>
