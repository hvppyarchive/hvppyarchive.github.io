<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.27.1 by Michael Rose
  Copyright 2013-2025 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>vLLM Cline 연결 디버깅 - ARCHIVE</title>
<meta name="description" content="">


  <meta name="author" content="hvppyarchive">
  
  <meta property="article:author" content="hvppyarchive">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="ARCHIVE">
<meta property="og:title" content="vLLM Cline 연결 디버깅">
<meta property="og:url" content="https://hvppyarchive.github.io/llm/vllm-cline-connection-debugging/">


  <meta property="og:description" content="">







  <meta property="article:published_time" content="2025-08-08T16:14:21+09:00">





  

  


<link rel="canonical" href="https://hvppyarchive.github.io/llm/vllm-cline-connection-debugging/">












<!-- end _includes/seo.html -->


<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->
<!-- hvppyarchive: add fonts -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif+KR:wght@200..900&display=swap" rel="stylesheet">

<!-- insert favicons. use https://realfavicongenerator.net/ -->
 <!-- hvppyarchive: add favicons -->
<link rel="icon" type="image/png" href="/assets/favicon/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/svg+xml" href="/assets/favicon/favicon.svg" />
<link rel="shortcut icon" href="/assets/favicon/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png" />
<link rel="manifest" href="/assets/favicon/site.webmanifest" />

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          ARCHIVE
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/year-archive/"
                
                
              >Posts</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="vLLM Cline 연결 디버깅">
    <meta itemprop="description" content="">
    <meta itemprop="datePublished" content="2025-08-08T16:14:21+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://hvppyarchive.github.io/llm/vllm-cline-connection-debugging/" itemprop="url">vLLM Cline 연결 디버깅
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-08T16:14:21+09:00">2025-08-08</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p class="chat--user">

vllm 서버에서 gpt-oss 120B 모델을 띄우고, 이 endpoint url에 VSCode Cline Extension을 연결해서 사용하고 있어.

</p>

<p>네, 상황을 정리하면 이렇게 되네요.</p>

<ol>
  <li>
    <p><strong>vLLM 서버</strong> 에서 <strong>gpt-oss 120B 모델</strong> 을 띄움</p>
  </li>
  <li>
    <p>그 모델의 <strong>endpoint URL</strong> 을 <strong>VSCode Cline Extension</strong> 에 연결해서 사용 중</p>
  </li>
</ol>

<p>이 구성이 동작하려면 크게 세 단계가 필요합니다.</p>

<hr />

<h2 id="1-vllm-서버에서-gpt-oss-120b-모델-실행">1. vLLM 서버에서 gpt-oss 120B 모델 실행</h2>

<ul>
  <li><strong>vLLM 설치</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>vllm
</code></pre></div>    </div>
  </li>
  <li><strong>모델 실행 예시</strong> (OpenAI API 호환 모드)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> vllm.entrypoints.openai.api_server <span class="se">\</span>
  <span class="nt">--model</span> gpt-oss-120b <span class="se">\</span>
  <span class="nt">--tensor-parallel-size</span> 4 <span class="se">\</span>
  <span class="nt">--port</span> 8000
</code></pre></div>    </div>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">--model</code> : Hugging Face 모델 경로 또는 로컬 경로</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">--tensor-parallel-size</code> : GPU 개수</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">--port</code> : API 서버 포트</p>
      </li>
    </ul>
  </li>
</ul>

<p>이렇게 하면 <code class="language-plaintext highlighter-rouge">http://&lt;서버IP&gt;:8000/v1</code> 엔드포인트가 생깁니다.</p>

<hr />

<h2 id="2-vscode-cline-extension-설정">2. VSCode Cline Extension 설정</h2>

<p>Cline은 OpenAI API 형식을 따르기 때문에, vLLM 서버가 OpenAI 호환 모드로 띄워져 있어야 합니다.</p>

<ul>
  <li>
    <p>VSCode → <strong>Cline Extension Settings</strong> → <strong>"API Provider"</strong>를 <code class="language-plaintext highlighter-rouge">OpenAI</code>로 선택</p>
  </li>
  <li><strong>API Base URL</strong> 을 vLLM 서버 주소로 설정:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>arduino
    
http://&lt;서버IP&gt;:8000/v1
</code></pre></div>    </div>
  </li>
  <li><strong>API Key</strong> 는 vLLM 서버에서 인증을 사용하지 않으면 아무 값이나 넣어도 됩니다.<br />
(예: <code class="language-plaintext highlighter-rouge">dummy-key</code>)</li>
</ul>

<hr />

<h2 id="3-연결-확인">3. 연결 확인</h2>

<p>터미널에서 다음 명령으로 정상 응답을 확인:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl http://&lt;서버IP&gt;:8000/v1/models
</code></pre></div></div>

<p>여기서 <code class="language-plaintext highlighter-rouge">gpt-oss-120b</code>가 뜨면 Cline에서도 바로 사용할 수 있습니다.</p>

<hr />

<p>💡 <strong>팁</strong></p>

<ul>
  <li>
    <p>로컬 개발 환경에서 GPU 부족 시, vLLM 대신 Hugging Face Text Generation Inference(TGI)도 OpenAI API 호환 모드로 쓸 수 있습니다.</p>
  </li>
  <li>
    <p>Cline이 <code class="language-plaintext highlighter-rouge">gpt-oss 120B</code> 같이 초대형 모델을 호출하면 응답이 느릴 수 있으니, 프롬프트를 최대한 압축하거나 서버 쪽에서 <code class="language-plaintext highlighter-rouge">--max-num-batched-tokens</code>를 조정하는 게 좋습니다.</p>
  </li>
</ul>

<hr />

<p>원하시면 제가 <strong>vLLM gpt-oss 120B + Cline 연결 전체 예제 설정 파일</strong> 을 만들어서 드릴 수 있습니다.<br />
이렇게 하면 서버 띄우고 바로 Cline에 붙일 수 있게 됩니다.</p>

<p class="chat--user">

그런데 관련해서 디버깅을 좀 해보고 싶어. Cline이 서버로 보내는 쿼리와 받는 정보를 raw data에 가깝게 볼 수 있을까?

</p>

<p>가능해요. “최대한 원본(raw)에 가깝게” 보려면 <strong>프록시를 사이에 둬서 요청/응답을 그대로 덤프</strong> 하는 게 가장 깔끔합니다. 아래를 순서대로 해보세요. (짧게 → 깊게)</p>

<hr />

<h1 id="0-한줄-요약">0) 한줄 요약</h1>

<ul>
  <li>
    <p><strong>권장:</strong> Cline ⇄ <strong>mitmproxy(reverse proxy)</strong> ⇄ vLLM</p>
  </li>
  <li>
    <p><strong>보너스:</strong> VSCode 로그(Extension Host/Window), 서버측(access log), 마지막 수단으로 <code class="language-plaintext highlighter-rouge">ngrep/tcpdump</code></p>
  </li>
</ul>

<hr />

<h1 id="1-mitmproxy로-전체-http-캡처권장">1) mitmproxy로 전체 HTTP 캡처(권장)</h1>

<p>Cline이 호출하는 OpenAI 호환 REST 요청을 <strong>바이트 단위로 시/헤더/바디/스트리밍까지</strong> 볼 수 있습니다.</p>

<h3 id="1-1-mitmproxy-설치">1-1. mitmproxy 설치</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>mitmproxy
<span class="c"># 또는 macOS: brew install mitmproxy</span>
</code></pre></div></div>

<h3 id="1-2-vllm-뒤에-리버스-프록시-세우기">1-2. vLLM 뒤에 리버스 프록시 세우기</h3>

<p>vLLM이 <code class="language-plaintext highlighter-rouge">http://&lt;VLLM_HOST&gt;:8000/v1</code> 라고 가정:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mitmproxy <span class="nt">-p</span> 8080 <span class="nt">--mode</span> reverse:http://&lt;VLLM_HOST&gt;:8000 <span class="nt">-w</span> cline_flows.mitm
<span class="c"># GUI 원하면:</span>
<span class="c"># mitmweb -p 8080 --mode reverse:http://&lt;VLLM_HOST&gt;:8000 -w cline_flows.mitm</span>
</code></pre></div></div>

<h3 id="1-3-cline의-base-url을-mitmproxy로-바꾸기">1-3. Cline의 Base URL을 mitmproxy로 바꾸기</h3>

<p>Cline의 <strong>API Base URL</strong> 을:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>http://localhost:8080/v1
</code></pre></div></div>

<p>로 설정합니다. (API Key는 dummy 가능)</p>

<blockquote>
  <p>이제 mitm 화면에서 각 요청/응답을 클릭해 <strong>Headers / Content / Raw</strong> 탭으로 모두 확인 가능.<br />
 SSE(스트리밍)도 “Raw”에서 줄 단위로 보입니다.</p>
</blockquote>

<h3 id="1-4-본문까지-파일로-떨구고-싶다면옵션">1-4. 본문까지 파일로 떨구고 싶다면(옵션)</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mitmdump <span class="nt">-p</span> 8080 <span class="nt">--mode</span> reverse:http://&lt;VLLM_HOST&gt;:8000 <span class="se">\</span>
  <span class="nt">-s</span> <span class="s1">'"""
from mitmproxy import http
def response(flow: http.HTTPFlow):
    with open("http_log.txt","ab") as f:
        f.write((f"\\n=== {flow.request.method} {flow.request.pretty_url} ===\\n").encode())
        f.write(flow.request.headers.bytes() + b"\\n\\n" + flow.request.raw_content + b"\\n")
        f.write(b"--- RESPONSE ---\\n")
        f.write(flow.response.headers.bytes() + b"\\n\\n" + (flow.response.raw_content or b"") + b"\\n")
"""'</span>
</code></pre></div></div>

<blockquote>
  <p><strong>주의:</strong> 본문에 토큰/프롬프트 등 민감정보가 포함됩니다. 로컬에서만 사용!</p>
</blockquote>

<hr />

<h1 id="2-초간단-로깅-프록시-직접-띄우기대체안">2) 초간단 “로깅 프록시” 직접 띄우기(대체안)</h1>

<p>외부 도구 없이, <strong>작은 Node 프록시</strong> 를 넣어도 됩니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># server.js</span>
const http <span class="o">=</span> require<span class="o">(</span><span class="s1">'http'</span><span class="o">)</span><span class="p">;</span>
const <span class="o">{</span> request: httpRequest <span class="o">}</span> <span class="o">=</span> require<span class="o">(</span><span class="s1">'http'</span><span class="o">)</span><span class="p">;</span>

const TARGET <span class="o">=</span> <span class="s1">'http://&lt;VLLM_HOST&gt;:8000'</span><span class="p">;</span>

http.createServer<span class="o">((</span>clientReq, clientRes<span class="o">)</span> <span class="o">=&gt;</span> <span class="o">{</span>
  <span class="nb">let </span>body <span class="o">=</span> <span class="o">[]</span><span class="p">;</span>
  clientReq.on<span class="o">(</span><span class="s1">'data'</span>, chunk <span class="o">=&gt;</span> body.push<span class="o">(</span>chunk<span class="o">))</span><span class="p">;</span>
  clientReq.on<span class="o">(</span><span class="s1">'end'</span>, <span class="o">()</span> <span class="o">=&gt;</span> <span class="o">{</span>
    body <span class="o">=</span> Buffer.concat<span class="o">(</span>body<span class="o">)</span><span class="p">;</span>
    console.log<span class="o">(</span><span class="s1">'\n=== REQUEST ==='</span><span class="o">)</span><span class="p">;</span>
    console.log<span class="o">(</span>clientReq.method, clientReq.url<span class="o">)</span><span class="p">;</span>
    console.log<span class="o">(</span>clientReq.headers<span class="o">)</span><span class="p">;</span>
    console.log<span class="o">(</span>body.toString<span class="o">())</span><span class="p">;</span>

    const opts <span class="o">=</span> <span class="o">{</span>
      method: clientReq.method,
      headers: clientReq.headers,
      path: clientReq.url,
      host: new URL<span class="o">(</span>TARGET<span class="o">)</span>.hostname,
      port: new URL<span class="o">(</span>TARGET<span class="o">)</span>.port,
    <span class="o">}</span><span class="p">;</span>

    const proxyReq <span class="o">=</span> httpRequest<span class="o">(</span>opts, proxyRes <span class="o">=&gt;</span> <span class="o">{</span>
      <span class="nb">let </span>resBody <span class="o">=</span> <span class="o">[]</span><span class="p">;</span>
      proxyRes.on<span class="o">(</span><span class="s1">'data'</span>, chunk <span class="o">=&gt;</span> <span class="o">{</span>
        resBody.push<span class="o">(</span>chunk<span class="o">)</span><span class="p">;</span>
        clientRes.write<span class="o">(</span>chunk<span class="o">)</span><span class="p">;</span> // 스트리밍 패스스루
      <span class="o">})</span><span class="p">;</span>
      proxyRes.on<span class="o">(</span><span class="s1">'end'</span>, <span class="o">()</span> <span class="o">=&gt;</span> <span class="o">{</span>
        resBody <span class="o">=</span> Buffer.concat<span class="o">(</span>resBody<span class="o">)</span><span class="p">;</span>
        console.log<span class="o">(</span><span class="s1">'\n--- RESPONSE ---'</span><span class="o">)</span><span class="p">;</span>
        console.log<span class="o">(</span>proxyRes.statusCode, proxyRes.headers<span class="o">)</span><span class="p">;</span>
        console.log<span class="o">(</span>resBody.toString<span class="o">())</span><span class="p">;</span>
        clientRes.end<span class="o">()</span><span class="p">;</span>
      <span class="o">})</span><span class="p">;</span>
    <span class="o">})</span><span class="p">;</span>

    proxyReq.on<span class="o">(</span><span class="s1">'error'</span>, e <span class="o">=&gt;</span> <span class="o">{</span>
      console.error<span class="o">(</span><span class="s1">'proxy error'</span>, e<span class="o">)</span><span class="p">;</span>
      clientRes.statusCode <span class="o">=</span> 502<span class="p">;</span>
      clientRes.end<span class="o">(</span><span class="s1">'proxy error'</span><span class="o">)</span><span class="p">;</span>
    <span class="o">})</span><span class="p">;</span>

    proxyReq.write<span class="o">(</span>body<span class="o">)</span><span class="p">;</span>
    proxyReq.end<span class="o">()</span><span class="p">;</span>
  <span class="o">})</span><span class="p">;</span>
<span class="o">})</span>.listen<span class="o">(</span>8080, <span class="o">()</span> <span class="o">=&gt;</span> console.log<span class="o">(</span><span class="s1">'logging proxy on :8080'</span><span class="o">))</span><span class="p">;</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>node server.js
<span class="c"># 그리고 Cline Base URL을 http://localhost:8080/v1 로</span>
</code></pre></div></div>

<hr />

<h1 id="3-vscode-쪽에서-볼-수-있는-로그">3) VSCode 쪽에서 볼 수 있는 로그</h1>

<ol>
  <li>
    <p><strong>Output 패널</strong></p>

    <ul>
      <li>
        <p>VSCode: View → Output → 드롭다운에서</p>

        <ul>
          <li><strong>“Log (Extension Host)”</strong> , <strong>“Log (Window)”</strong> , 혹시 있다면 <strong>“Cline”</strong> 채널 확인</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>로그 레벨 올리기</strong></p>

    <ul>
      <li>Settings에서 <strong>“Log Level” → “Trace”</strong>로 설정</li>
    </ul>
  </li>
  <li>
    <p><strong>Developer Tools</strong></p>

    <ul>
      <li>
        <p>Help → Toggle Developer Tools → Console 탭</p>
      </li>
      <li>
        <p>일부 네트워크/콘솔 로그가 찍힙니다(확장 작동 방식에 따라 차이)</p>
      </li>
    </ul>
  </li>
</ol>

<blockquote>
  <p>확장마다 남기는 로그 범위가 달라 실제 <strong>요청/응답 바디 전체</strong> 는 안 나올 수 있어요. 그래서 위의 <strong>프록시 접근이 가장 확실</strong> 합니다.</p>
</blockquote>

<hr />

<h1 id="4-서버vllm-측-로그를-좀-더-보기">4) 서버(vLLM) 측 로그를 좀 더 보기</h1>

<ul>
  <li>
    <p>vLLM OpenAI 서버는 Uvicorn 위에서 돌아가므로 <strong>access log</strong> 는 기본적으로 나옵니다.</p>
  </li>
  <li>
    <p>더 자세히 보려면(바디는 기본 미포함):</p>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> vllm.entrypoints.openai.api_server <span class="se">\</span>
  <span class="nt">--model</span> gpt-oss-120b <span class="se">\</span>
  <span class="nt">--port</span> 8000 <span class="se">\</span>
  <span class="nt">--log-level</span> debug
</code></pre></div>    </div>
  </li>
</ul>

<blockquote>
  <p>이건 라우트/상태 정도만 보이고, <strong>요청/응답 바디는 노출되지 않습니다.</strong><br />
 원본 바디가 필요하면 1번(프록시)로 가는 게 정석.</p>
</blockquote>

<hr />

<h1 id="5-네트워크-레벨에서-그냥-까보기http일-때만">5) 네트워크 레벨에서 “그냥 까보기”(HTTP일 때만)</h1>

<p>서버와 Cline 사이가 <strong>평문 HTTP</strong> 라면, 패킷 레벨로도 확인 가능합니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ngrep</code> (가독성 좋음)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>ngrep <span class="nt">-d</span> any <span class="nt">-W</span> byline port 8000
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">tcpdump</code> (바이너리/헤더까지)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>tcpdump <span class="nt">-A</span> <span class="nt">-s0</span> <span class="s1">'tcp port 8000'</span>
</code></pre></div>    </div>
  </li>
</ul>

<blockquote>
  <p>HTTPS라면 내용은 해독이 안 되니 프록시가 필요합니다.</p>
</blockquote>

<hr />

<h1 id="6-재현용-curl로-같은-요청-만들어보기">6) 재현용: curl로 같은 요청 만들어보기</h1>

<p>Cline이 보내는 페이로드를 캡처했으면, <strong>동일한 요청</strong> 을 <code class="language-plaintext highlighter-rouge">curl</code>로 반복 재현하면서 비교 디버깅하기 좋습니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-v</span> http://localhost:8080/v1/chat/completions <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Authorization: Bearer dummy"</span> <span class="se">\</span>
  <span class="nt">-d</span> <span class="s1">'{
    "model": "gpt-oss-120b",
    "messages": [{"role":"user","content":"hello"}],
    "stream": true
  }'</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">-v</code>/<code class="language-plaintext highlighter-rouge">--trace-ascii dump.txt</code>로 <strong>wire-level</strong> 로그 확보 가능</li>
</ul>

<hr />

<h2 id="어떤-방법이-제일-나을까">어떤 방법이 제일 나을까?</h2>

<ul>
  <li>
    <p><strong>가장 확실하고 빠른 해법은 1) mitmproxy reverse</strong> 입니다. UI로 한눈에 보이고, 파일로도 저장 가능.</p>
  </li>
  <li>
    <p>VSCode 로그는 “보조”.</p>
  </li>
  <li>
    <p>서버 로그/패킷 스니핑은 상황 따라 도움.</p>
  </li>
</ul>

<p>원하시면, <strong>현재 환경(IP/포트/HTTPS 여부)</strong> 알려주면 제가 <strong>딱 맞춘 명령어와 Cline 설정 스크린샷 가이드</strong> 까지 만들어드릴게요.</p>

<p class="chat--user">

API 키 입력이 필요하면?

</p>

<p>Cline이 API 키를 <strong>반드시</strong> 요구하는 경우라도, vLLM 서버가 인증을 쓰지 않는다면 사실상 <strong>아무 문자열이나 넣으면 됩니다.</strong><br />
왜냐면 vLLM의 OpenAI 호환 API는 기본적으로 API 키 검증을 하지 않기 때문이에요.</p>

<hr />

<h2 id="1-인증-없는-vllm-서버일-때">1. 인증 없는 vLLM 서버일 때</h2>

<ul>
  <li>
    <p>Cline의 API Key 입력칸에 <code class="language-plaintext highlighter-rouge">dummy</code> 또는 <code class="language-plaintext highlighter-rouge">test</code>처럼 아무 값 입력</p>
  </li>
  <li>
    <p>mitmproxy/프록시/서버 모두 그대로 통과합니다.</p>
  </li>
  <li>
    <p>요청 헤더 예시:</p>
    <div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">Authorization</span><span class="o">:</span> <span class="nf">Bearer dummy</span>
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="2-vllm에서-api-키-검증을-켠-경우">2. vLLM에서 API 키 검증을 켠 경우</h2>

<p>만약 <code class="language-plaintext highlighter-rouge">--api-key</code> 같은 인증 옵션을 활성화했다면(또는 API Gateway 뒤에 둔 경우):</p>

<ol>
  <li><strong>서버에서 설정한 키</strong> 를 기억하거나 환경변수로 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">VLLM_API_KEY</span><span class="o">=</span><span class="s2">"my-secret-key"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Cline API Key 입력란에 해당 키를 입력</p>
  </li>
  <li>프록시나 mitmproxy로 캡처 시에도 이 키가 그대로 Authorization 헤더에 뜹니다.</li>
</ol>

<hr />

<h2 id="3-디버깅-프록시에서-키를-안전하게-처리하는-팁">3. 디버깅 프록시에서 키를 안전하게 처리하는 팁</h2>

<ul>
  <li>요청 로깅 시 Authorization 헤더를 <strong>마스킹</strong> 하면 좋습니다.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># mitmproxy 스크립트 예시
</span><span class="kn">from</span> <span class="n">mitmproxy</span> <span class="kn">import</span> <span class="n">http</span>
<span class="k">def</span> <span class="nf">request</span><span class="p">(</span><span class="n">flow</span><span class="p">:</span> <span class="n">http</span><span class="p">.</span><span class="n">HTTPFlow</span><span class="p">):</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">authorization</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">flow</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">headers</span><span class="p">:</span>
        <span class="n">flow</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">headers</span><span class="p">[</span><span class="sh">"</span><span class="s">authorization</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Bearer ***MASKED***</span><span class="sh">"</span>
</code></pre></div>    </div>
  </li>
  <li>내부 개발/로컬 환경이면 그냥 그대로 봐도 무방하지만, 키가 외부로 유출되면 안 됩니다.</li>
</ul>

<hr />

<p>📌 <strong>결론</strong></p>

<ul>
  <li>
    <p>인증 없으면 Cline에 임의 문자열 넣으면 끝.</p>
  </li>
  <li>
    <p>인증 있으면 vLLM 서버에 설정한 키를 넣어야 함.</p>
  </li>
  <li>
    <p>디버깅 시엔 프록시에서 키를 가려주는 습관을 들이면 안전합니다.</p>
  </li>
</ul>

<hr />

<p>필요하다면 제가 <strong>API 키 유무별 Cline–vLLM–mitmproxy 연결 전체 그림</strong> 을 그려서, 어떤 값이 어디로 흘러가는지 보여드릴 수 있습니다.<br />
그렇게 하면 디버깅 흐름이 한눈에 보입니다.</p>

<p class="chat--user">

했는데 API Streaming Failed Unexpected token 173781 while expecting start token 200006 에러가 떠 cline에서

</p>

<p>이 증상, 거의 100% <strong>스트리밍 파서/포맷 불일치</strong> 예요.<br />
특히 메시지에 나온 <code class="language-plaintext highlighter-rouge">start token 200006</code>는 OpenAI o-series(=gpt-4o 계열) 토크나이저의 특수 토큰 ID라서, <strong>Cline이 o-series/Harmony 포맷을 기대</strong> 하는데 vLLM의 <strong>일반 Chat Completions 스트림</strong> 을 받는 경우에 잘 터집니다. <a href="https://docs.cline.bot/provider-config/openai-compatible?utm_source=chatgpt.com">docs.cline.bot</a><a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html?utm_source=chatgpt.com">VLLM Docs</a></p>

<p>아래 순서대로 체크해보세요. (위에서부터 한 단계씩)</p>

<hr />

<h3 id="1-cline가-responses-api-가-아니라-chat-completions-를-때리게-만들기">1) Cline가 <strong>Responses API</strong> 가 아니라 <strong>Chat Completions</strong> 를 때리게 만들기</h3>

<ul>
  <li>
    <p>Cline 설정 → <strong>API Provider: OpenAI Compatible</strong></p>
  </li>
  <li>
    <p><strong>Base URL</strong> : <code class="language-plaintext highlighter-rouge">http://&lt;서버IP&gt;:8000/v1</code></p>
  </li>
  <li>
    <p><strong>Model ID</strong> : vLLM에 띄운 <strong>정확한 이름</strong>(예: <code class="language-plaintext highlighter-rouge">gpt-oss-120b</code>)</p>
  </li>
  <li>
    <p>가능하면 <strong>Responses API(“/v1/responses”) 옵션/모드 꺼두기</strong> → vLLM은 공식적으로 <strong>/v1/chat/completions</strong> 스트림을 지원합니다. <a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html?utm_source=chatgpt.com">VLLM Docs</a></p>
  </li>
</ul>

<blockquote>
  <p>왜? vLLM의 OpenAI 호환 서버는 Completions/Chat/Embeddings까지만 구현되어 있고, OpenAI의 최신 <strong>Responses/Harmony(o-series)</strong> 이벤트 스트림과는 필드/이벤트명이 달라서 Cline 파서가 못 알아듣습니다. <a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html?utm_source=chatgpt.com">VLLM Docs</a></p>
</blockquote>

<hr />

<h3 id="2-cline에서-o-seriesreasoningcomputer-use병렬-툴콜-꺼두기">2) Cline에서 “o-series/Reasoning/Computer Use/병렬 툴콜” 꺼두기</h3>

<ul>
  <li>
    <p>모델을 <strong>o1/o3/gpt-4o</strong> 류가 아닌 <strong>일반 채팅형</strong> 으로 고정</p>
  </li>
  <li>
    <p><strong>Tool/Computer Use</strong> 기능을 일단 <strong>OFF</strong> (vLLM의 함수/툴콜 구현과 Cline의 기대치가 어긋날 수 있음)</p>
  </li>
</ul>

<hr />

<h3 id="3-스트리밍-자체가-문제인지-분리">3) 스트리밍 자체가 문제인지 분리</h3>

<ul>
  <li>
    <p>Cline 설정에서 <strong>Stream 비활성화</strong> 가 가능하면 잠시 꺼서 테스트</p>
  </li>
  <li>
    <p>혹은 동일 요청을 <strong>curl로 재현</strong> 해 보세요:</p>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 스트림 OFF로 테스트(파서 우회)</span>
curl http://&lt;서버IP&gt;:8000/v1/chat/completions <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Authorization: Bearer dummy"</span> <span class="se">\</span>
  <span class="nt">-d</span> <span class="s1">'{
    "model":"gpt-oss-120b",
    "messages":[{"role":"user","content":"ping"}],
    "stream": false
  }'</span>
</code></pre></div>    </div>
  </li>
</ul>

<p>이건 잘 되는데 Cline에서만 터지면 <strong>Cline의 SSE 파서/옵션 불일치</strong> 로 확정.</p>

<hr />

<h3 id="4-mitmproxy로-실제-스트림-모양-확인">4) mitmproxy로 실제 스트림 모양 확인</h3>

<ul>
  <li>Cline ↔ vLLM 사이에 <strong>mitmproxy(reverse)</strong>를 두고 <strong>SSE 라인</strong> 을 봅니다.<br />
<code class="language-plaintext highlighter-rouge">data: { ... }</code>가 JSON 청크로 오다가 마지막에 <code class="language-plaintext highlighter-rouge">data: [DONE]</code>으로 끝나야 Cline이 행복합니다. 만약 <strong>Responses API 이벤트명</strong>(예: <code class="language-plaintext highlighter-rouge">event: response.delta</code>) 비슷한 게 보이면 라우팅이 잘못된 겁니다. <a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html?utm_source=chatgpt.com">VLLM Docs</a></li>
</ul>

<hr />

<h3 id="5-vllm-서버-쪽-권장-실행-플래그">5) vLLM 서버 쪽 권장 실행 플래그</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> vllm.entrypoints.openai.api_server <span class="se">\</span>
  <span class="nt">--model</span> gpt-oss-120b <span class="se">\</span>
  <span class="nt">--host</span> 0.0.0.0 <span class="nt">--port</span> 8000 <span class="se">\</span>
  <span class="nt">--tensor-parallel-size</span> &lt;GPU수&gt; <span class="se">\</span>
  <span class="nt">--enable-log-requests</span>  <span class="c">#(문제시 요청 로깅 보조)</span>
</code></pre></div></div>

<ul>
  <li>반드시 Cline이 <strong>/v1/chat/completions</strong> 로 치는지 확인하세요. (mitmproxy/curl)</li>
</ul>

<hr />

<h3 id="6-흔한-함정-정리">6) 흔한 함정 정리</h3>

<ul>
  <li>
    <p><strong>Base URL 끝에 /v1 빠짐</strong> → 404/파서오류 유발</p>
  </li>
  <li>
    <p><strong>Model ID 오타</strong> → 일부 게이트웨이는 다른 엔드포인트로 우회 응답</p>
  </li>
  <li>
    <p><strong>JSON 모드/Response Format 강제</strong>(예: json_schema) → 일부 모델에서 스트림 형식이 달라져 파서 에러</p>
  </li>
  <li>
    <p><strong>HTTP 압축/프록시 변환</strong> 이 SSE 줄바꿈을 깨뜨리는 경우</p>
  </li>
</ul>

<hr />

<h3 id="왜-200006이-보였나">왜 200006이 보였나?</h3>

<p>o-series(Harmony) 포맷에서 쓰는 특수 토큰 ID들이 있고, 글 중에도 <code class="language-plaintext highlighter-rouge">200006</code> 같은 ID가 언급됩니다. Cline이 그 <strong>포맷(=특정 토큰 경계/이벤트)을 기대</strong> 했는데, vLLM이 <strong>일반 Chat 스트림</strong> 을 보내니 “기대하던 시작 토큰이 아니다” 류의 에러가 난 것으로 추정됩니다. <a href="https://simonwillison.net/2025/Aug/5/gpt-oss/?utm_source=chatgpt.com">Simon Willison’s Weblog</a></p>

<hr />

<p>필요하면 지금 Cline 설정 스크린샷(모델/엔드포인트/토글 항목)과 <strong>mitmproxy 캡처</strong> 한두 건만 올려 주세요.<br />
그대로 보고 <strong>“어느 지점에서 Responses↔Chat이 엇갈리는지”</strong> 정확히 짚어드릴게요.</p>

<p class="chat--user">

근데 mitmproxy를 안쓰면 저 에러가 안나

</p>

<p>오—그럼 <strong>원인 범위가 mitmproxy 쪽</strong> 으로 꽤 좁혀졌어요.<br />
SSE(서버센트 이벤트) 스트림을 mitmproxy가 <strong>버퍼링/재인코딩/HTTP2 변환</strong> 하면서 Cline의 파서가 기대하는 포맷이 깨지는 전형적인 케이스 같습니다.</p>

<p>아래 순서대로 “한 가지씩” 바꿔 보세요. (위에서부터 효과 큰 것 ▶ 세부)</p>

<hr />

<h2 id="1-mitmproxy-실행-옵션을-스트리밍-친화적으로-바꾸기">1) mitmproxy 실행 옵션을 스트리밍 친화적으로 바꾸기</h2>

<p>SSE는 라인 경계(줄바꿈)와 chunking이 아주 민감해요. 다음 옵션이 핵심입니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mitmproxy <span class="se">\</span>
  <span class="nt">--mode</span> reverse:http://&lt;VLLM_HOST&gt;:8000 <span class="se">\</span>
  <span class="nt">-p</span> 8080 <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">http2</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">connection_strategy</span><span class="o">=</span>lazy <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">stream_large_bodies</span><span class="o">=</span>1
</code></pre></div></div>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">http2=false</code> : 업스트림/다운스트림에서 HTTP/2로 변환되는 걸 막아서 <strong>SSE 라인 경계 깨짐</strong> 을 예방</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">connection_strategy=lazy</code> : 불필요한 선연결/재사용 줄임</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">stream_large_bodies=1</code> : <strong>응답을 버퍼링하지 말고 바로바로 흘려보냄</strong> (SSE 필수)</p>
  </li>
</ul>

<blockquote>
  <p>Cline Base URL은 <code class="language-plaintext highlighter-rouge">http://localhost:8080/v1</code> 로 유지</p>
</blockquote>

<hr />

<h2 id="2-바디-찍는-mitm-스크립트는-일단-끄기">2) “바디 찍는” mitm 스크립트는 일단 끄기</h2>

<p>제가 전에 드린 예시처럼 <code class="language-plaintext highlighter-rouge">flow.response.raw_content</code>를 파일로 쓰면 <strong>mitm이 본문을 수집하려고 버퍼링</strong> 할 수 있어요.<br />
<strong>스크립트 없이</strong> UI에서 Raw 탭으로 먼저 확인해 보세요.<br />
(로그를 꼭 남겨야 한다면, <code class="language-plaintext highlighter-rouge">responseheaders</code> 이벤트에서 헤더만 찍고 바디는 건드리지 않는 방식으로…)</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># headers만 로깅(버퍼링 방지)
</span><span class="kn">from</span> <span class="n">mitmproxy</span> <span class="kn">import</span> <span class="n">http</span>
<span class="k">def</span> <span class="nf">responseheaders</span><span class="p">(</span><span class="n">flow</span><span class="p">:</span> <span class="n">http</span><span class="p">.</span><span class="n">HTTPFlow</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">=== RESPONSE HEADERS ===</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">flow</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="p">,</span> <span class="nf">dict</span><span class="p">(</span><span class="n">flow</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">headers</span><span class="p">))</span>
    <span class="c1"># 스트리밍 강제
</span>    <span class="n">flow</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">stream</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre></div></div>

<hr />

<h2 id="3-gzip인코딩-간섭-줄이기">3) gzip/인코딩 간섭 줄이기</h2>

<p>가능하면 Cline 쪽에서 <strong>Accept-Encoding: identity</strong> 를 강제하거나, vLLM이 <code class="language-plaintext highlighter-rouge">text/event-stream</code>에 대해 압축을 안 하도록(기본적으로는 안 함) 둡니다.<br />
압축이 끼면 중간 프록시가 <strong>재압축/해제</strong> 하면서 줄 경계가 어긋날 수 있어요.</p>

<hr />

<h2 id="4-프록시-경로중복-prefix-확인">4) 프록시 경로/중복 prefix 확인</h2>

<p>reverse 모드에서 <strong>Base URL이<code class="language-plaintext highlighter-rouge">/v1</code></strong> 인데, upstream에도 <code class="language-plaintext highlighter-rouge">/v1</code>가 붙은 주소로 중복되면 라우팅 꼬입니다.</p>

<ul>
  <li>
    <p>mitmproxy: <code class="language-plaintext highlighter-rouge">--mode reverse:http://&lt;VLLM_HOST&gt;:8000</code></p>
  </li>
  <li>
    <p>Cline Base URL: <code class="language-plaintext highlighter-rouge">http://localhost:8080/v1</code></p>
  </li>
  <li>
    <p><strong>Upstream vLLM 라우트는<code class="language-plaintext highlighter-rouge">/v1/chat/completions</code></strong> 로 딱 한 번만 들어가야 합니다.</p>
  </li>
</ul>

<hr />

<h2 id="5-재현-테스트-직접-curl로-cline-대신-쏘기">5) 재현 테스트 (직접 curl로 Cline 대신 쏘기)</h2>

<p>mitm를 끼웠을 때만 깨지는지, 그리고 옵션 수정 후 복구됐는지 빠르게 확인:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Stream 켠 채로 mitm 경유</span>
curl <span class="nt">-N</span> <span class="nt">-v</span> http://localhost:8080/v1/chat/completions <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Content-Type: application/json"</span> <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Authorization: Bearer dummy"</span> <span class="se">\</span>
  <span class="nt">-d</span> <span class="s1">'{ "model":"gpt-oss-120b",
        "messages":[{"role":"user","content":"ping"}],
        "stream": true }'</span>
</code></pre></div></div>

<p>정상이라면 이런 패턴으로 흘러와야 합니다:</p>
<div class="language-kotlin highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">:</span> <span class="p">{</span><span class="s">"id"</span><span class="p">:</span><span class="s">"..."</span><span class="p">,</span><span class="s">"object"</span><span class="p">:</span><span class="s">"chat.completion.chunk"</span><span class="p">,</span> <span class="o">..</span><span class="p">.}</span>
<span class="n">data</span><span class="p">:</span> <span class="p">{</span><span class="s">"id"</span><span class="p">:</span><span class="s">"..."</span><span class="p">,</span><span class="s">"object"</span><span class="p">:</span><span class="s">"chat.completion.chunk"</span><span class="p">,</span> <span class="o">..</span><span class="p">.}</span>
<span class="o">..</span><span class="p">.</span>
<span class="n">data</span><span class="p">:</span> <span class="p">[</span><span class="nc">DONE</span><span class="p">]</span>
</code></pre></div></div>

<hr />

<h2 id="6-그래도-안-되면-대안-2가지">6) 그래도 안 되면: 대안 2가지</h2>

<ul>
  <li>
    <p><strong>HTTP/1.1 고정 프록시</strong>(tinyproxy/nginx/HAProxy)로 단순 패스스루만 하게 하기</p>

    <ul>
      <li>nginx 예: <code class="language-plaintext highlighter-rouge">proxy_http_version 1.1; proxy_set_header Connection ""; proxy_buffering off;</code></li>
    </ul>
  </li>
  <li>
    <p><strong>ngrep/tcpdump</strong> 로 패킷 레벨 캡처(프록시 없이도 raw 확인 가능)</p>
  </li>
</ul>

<hr />

<h2 id="7-체크리스트한-번에-훑기">7) 체크리스트(한 번에 훑기)</h2>

<ul>
  <li>
    <p>mitm <code class="language-plaintext highlighter-rouge">http2=false</code>, <code class="language-plaintext highlighter-rouge">stream_large_bodies=1</code> 적용</p>
  </li>
  <li>
    <p>커스텀 mitm 스크립트에서 <strong>본문 접근 제거</strong> (헤더만 로깅)</p>
  </li>
  <li>
    <p>Base URL 경로 중복 없음(<code class="language-plaintext highlighter-rouge">/v1</code> 한 번만)</p>
  </li>
  <li>
    <p>SSE 응답 헤더 확인: <code class="language-plaintext highlighter-rouge">Content-Type: text/event-stream</code>, <code class="language-plaintext highlighter-rouge">Cache-Control: no-cache</code></p>
  </li>
  <li>
    <p>gzip/deflate 비활성화(가능하다면)</p>
  </li>
  <li>
    <p>Cline이 <strong>/v1/responses</strong> 가 아닌 <strong>/v1/chat/completions</strong> 로 호출 중</p>
  </li>
</ul>

<hr />

<p>원하시면 지금 쓰신 mitm 실행 커맨드랑(옵션 포함), Cline Base URL/모델 설정을 알려주세요.<br />
그대로 맞춰서 <strong>오류 재현 → 최소 수정 세트</strong> 를 딱 뽑아드릴게요.</p>

<p class="chat--user">

http2=false 옵션 하나만 추가하니 잘 돼네

</p>

<p>아, 그럼 원인이 거의 확정이네요 — <strong>mitmproxy가 기본으로 HTTP/2로 업스트림 연결</strong> 을 시도하면서 SSE(서버센트 이벤트) 스트림의 줄 경계나 전송 방식이 미묘하게 변형돼서, Cline 파서가 깨졌던 겁니다.</p>

<hr />

<h2 id="왜-http2false로-해결됐나">왜 <code class="language-plaintext highlighter-rouge">http2=false</code>로 해결됐나</h2>

<ul>
  <li>
    <p>SSE는 <strong>HTTP/1.1의 chunked transfer</strong> 에 의존하는 경우가 많습니다.</p>
  </li>
  <li>
    <p>mitmproxy가 HTTP/2로 업스트림을 붙으면, 내부에서 <strong>프레임 단위로 전송</strong> → 중간에 라인 경계(<code class="language-plaintext highlighter-rouge">\n\n</code>)가 바뀌거나 버퍼링 타이밍이 달라짐.</p>
  </li>
  <li>
    <p>특히 Cline 같이 실시간 토큰 단위 파서를 쓰는 쪽은 이 변화에 민감해서, <strong>"Unexpected token"</strong> 같은 오류를 뿜습니다.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">--set http2=false</code>는 mitmproxy가 업/다운 스트림 모두 <strong>HTTP/1.1로 고정</strong> 하게 해서 원본 chunking/SSE 형식을 보존하게 만듭니다.</p>
  </li>
</ul>

<hr />

<h2 id="안전하게-쓰는-mitmproxy-sse-프록시-실행-예시">안전하게 쓰는 mitmproxy SSE 프록시 실행 예시</h2>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mitmproxy <span class="se">\</span>
  <span class="nt">--mode</span> reverse:http://&lt;VLLM_HOST&gt;:8000 <span class="se">\</span>
  <span class="nt">-p</span> 8080 <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">http2</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">connection_strategy</span><span class="o">=</span>lazy <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">stream_large_bodies</span><span class="o">=</span>1
</code></pre></div></div>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">connection_strategy=lazy</code> → 불필요한 선연결 방지</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">stream_large_bodies=1</code> → 응답 버퍼링 없이 바로 흘려보냄</p>
  </li>
</ul>

<hr />

<h2 id="앞으로-비슷한-상황-방지-팁">앞으로 비슷한 상황 방지 팁</h2>

<ol>
  <li>
    <p><strong>SSE 프록시에는 HTTP/2 강제 비활성</strong></p>
  </li>
  <li>
    <p>본문 로깅이 필요하면 <strong>stream 모드에서 헤더만 찍고 바디는 건드리지 않기</strong></p>
  </li>
  <li>
    <p>gzip/deflate 같은 압축은 가급적 꺼두기 → 중간 해제 시 줄 경계 깨짐 방지</p>
  </li>
  <li>
    <p>프록시로 테스트한 curl 요청이 정상 스트리밍이면, Cline에서도 99% 잘 동작</p>
  </li>
</ol>

<hr />

<p>이제 <code class="language-plaintext highlighter-rouge">http2=false</code>로 고정한 상태에서 디버깅 로그 수집도 문제없이 가능할 거예요.<br />
원하시면 제가 <strong>Cline↔mitmproxy↔vLLM 흐름도</strong> 그려서, 데이터가 어떻게 흘러가고 어디서 줄 경계가 깨지는지 시각적으로 보여드릴 수도 있습니다.</p>

        
      </section>

      <footer class="page__meta">
        
        


  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#llm" class="page__taxonomy-item p-category" rel="tag">llm</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2025-08-08T16:14:21+09:00">2025-08-08</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/misc/ipad-memo-app-shortcuts/" class="pagination--pager" title="아이패드 메모 앱 단축키">Previous</a>
    
    
      <a href="/llm/reasoning-effort-test/" class="pagination--pager" title="Reasoning effort 실험 계획">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
    
<div class="page__related">
  
  <h2 class="page__related-title">You may also enjoy</h2>
  <div class="grid__wrapper">
    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/2025-08-19-python-repr-vs-str/" rel="permalink">
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-29T20:13:20+09:00">2025-08-29</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/misc/work-directory-structure/" rel="permalink">작업 폴더 구성 추천
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-29T20:13:15+09:00">2025-08-29</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/utils/utils-today/" rel="permalink">Today 업무 보조 툴
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-29T16:18:01+09:00">2025-08-29</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

</p>
  </article>
</div>

    
      
      



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/linux/tcsh-run-check/" rel="permalink">tcsh 스크립트 실행 및 위치 파악
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <!-- hvppyarchive: remove date icon
        <i class="far fa-calendar-alt" aria-hidden="true"></i> 
        -->
        
        <time datetime="2025-08-28T19:09:08+09:00">2025-08-28</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

</p>
  </article>
</div>

    
  </div>
</div>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
  </ul>
</div>


<div class="page__footer-copyright">&copy; 2013 - 2025 <a href="https://hvppyarchive.github.io">ARCHIVE</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>






  </body>
</html>
